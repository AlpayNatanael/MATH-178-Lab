{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "534dbfc1",
   "metadata": {},
   "source": [
    "# Lab 4 (Student Version)\n",
    "\n",
    "Work in groups of up to **2** students, but each student should submit their own work.\n",
    "\n",
    "Put the full names of everyone in your group here.\n",
    "\n",
    "**Names**:\n",
    "- \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826faae8",
   "metadata": {},
   "source": [
    "## Part A: Train an XOR network using PyTorch\n",
    "\n",
    "**Goal:** Use PyTorch to train a neural network that correctly predicts XOR for all 4 inputs (**4 out of 4 correct**).\n",
    "\n",
    "**Requirements**\n",
    "- Use a **Binary Cross Entropy** loss (e.g., `nn.BCELoss()` or `nn.BCEWithLogitsLoss()`).\n",
    "- You must **train** the network (do not manually set weights).\n",
    "- Show the final predictions and the final accuracy.\n",
    "\n",
    "**What to turn in**\n",
    "- Your code.\n",
    "- A short answer (2–6 sentences) explaining what architecture + training setup you used, and what finally worked.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1174f861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2a9ac4",
   "metadata": {},
   "source": [
    "### A1) Create the XOR dataset\n",
    "\n",
    "Fill in the XOR input points and labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eccc47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: define the XOR inputs (shape: 4 x 2) as float tensors\n",
    "X = torch.tensor([\n",
    "    # [0., 0.],\n",
    "    # [1., 0.],\n",
    "    # [0., 1.],\n",
    "    # [1., 1.],\n",
    "])\n",
    "\n",
    "# TODO: define the XOR labels (shape: 4 x 1) as float tensors\n",
    "y_true = torch.tensor([\n",
    "    # [0.],\n",
    "    # [1.],\n",
    "    # [1.],\n",
    "    # [0.],\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decbc8d1",
   "metadata": {},
   "source": [
    "### A2) Define your model\n",
    "\n",
    "Hints:\n",
    "- XOR is not linearly separable, so you need **at least one hidden layer** and a **nonlinearity** (ReLU, Tanh, etc.).\n",
    "- If you use `nn.BCELoss()`, the model output should be in (0,1), so include a `Sigmoid()` at the end.\n",
    "- If you use `nn.BCEWithLogitsLoss()`, **do not** use `Sigmoid()` in the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e097fda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: build a small network for XOR\n",
    "# Example structure (edit it): Linear -> activation -> Linear -> (Sigmoid)\n",
    "\n",
    "d_in = 2\n",
    "d_hidden = None  # TODO: choose a hidden size (e.g., 2, 4, 8, ...)\n",
    "d_out = 1\n",
    "\n",
    "model = nn.Sequential(\n",
    "    # TODO: add layers\n",
    ")\n",
    "\n",
    "model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed9e979",
   "metadata": {},
   "source": [
    "### A3) Train the model\n",
    "\n",
    "Requirements:\n",
    "- Choose an optimizer (SGD or Adam).\n",
    "- Train long enough to get 4/4 correct.\n",
    "- Print (or store) the loss occasionally so we can see training progress.\n",
    "\n",
    "Tip: If SGD is unstable, try Adam, or change the learning rate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2201fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: choose a loss function\n",
    "# Option 1 (probability output): nn.BCELoss()\n",
    "# Option 2 (logits output): nn.BCEWithLogitsLoss()\n",
    "loss_fn = None\n",
    "\n",
    "# TODO: choose an optimizer\n",
    "optimizer = None\n",
    "\n",
    "# TODO: training loop\n",
    "num_steps = None  # TODO: choose number of steps/iterations\n",
    "\n",
    "for step in range(num_steps):\n",
    "    # Forward pass\n",
    "    y_hat = model(X)\n",
    "\n",
    "    # Loss\n",
    "    loss = loss_fn(y_hat, y_true)\n",
    "\n",
    "    # Backprop\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Optional: print progress\n",
    "    if step % 100 == 0:\n",
    "        print(step, float(loss))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a03661",
   "metadata": {},
   "source": [
    "### A4) Evaluate XOR accuracy\n",
    "\n",
    "Compute:\n",
    "- predicted probabilities\n",
    "- predicted labels (use threshold 0.5)\n",
    "- accuracy out of 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8e9c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: compute probabilities (or logits) and convert to predicted labels\n",
    "with torch.no_grad():\n",
    "    y_hat = model(X)\n",
    "\n",
    "# TODO: if y_hat are probabilities, threshold at 0.5\n",
    "# TODO: if y_hat are logits, apply sigmoid first, then threshold at 0.5\n",
    "y_pred = None\n",
    "\n",
    "# TODO: compute accuracy\n",
    "accuracy = None\n",
    "\n",
    "print(\"y_hat =\", y_hat)\n",
    "print(\"y_pred =\", y_pred)\n",
    "print(\"y_true =\", y_true)\n",
    "print(\"Accuracy =\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74667d78",
   "metadata": {},
   "source": [
    "**Short answers (write in markdown below):**\n",
    "1. What model architecture did you use (layers/activations)?\n",
    "2. What optimizer + learning rate did you use?\n",
    "3. Why does XOR need a nonlinearity?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14c6e4a",
   "metadata": {},
   "source": [
    "## Part B: Train an MNIST network using PyTorch\n",
    "\n",
    "**Goal:** Adapt the PyTorch tutorial approach to train an MNIST classifier and reach **at least 91% test accuracy**.\n",
    "\n",
    "Use `datasets.MNIST` (not FashionMNIST).\n",
    "\n",
    "Recommended reference:\n",
    "- PyTorch quickstart tutorial (structure for loaders/train/test loops).\n",
    "\n",
    "**What to turn in**\n",
    "- Your code.\n",
    "- Final test accuracy (as a number).\n",
    "- A short answer (4–8 sentences) describing what you changed to reach ≥91%.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967b536a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de7b95e",
   "metadata": {},
   "source": [
    "### B1) Load MNIST\n",
    "\n",
    "Create:\n",
    "- `training_data` (train=True)\n",
    "- `test_data` (train=False)\n",
    "\n",
    "Use `transform=ToTensor()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2dd2f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: load MNIST train and test datasets\n",
    "training_data = None\n",
    "test_data = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a01a53",
   "metadata": {},
   "source": [
    "### B2) Create DataLoaders\n",
    "\n",
    "Choose a batch size and create:\n",
    "- `train_dataloader`\n",
    "- `test_dataloader`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd67f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = None  # TODO\n",
    "\n",
    "train_dataloader = None  # TODO\n",
    "test_dataloader = None   # TODO\n",
    "\n",
    "# Optional: inspect one batch\n",
    "# for X, y in test_dataloader:\n",
    "#     print(X.shape, y.shape)\n",
    "#     break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990f5b35",
   "metadata": {},
   "source": [
    "### B3) Define your model\n",
    "\n",
    "Hints:\n",
    "- A simple start is: `Flatten -> Linear -> ReLU -> Linear -> ReLU -> Linear(10)`.\n",
    "- You can also try other architectures, but keep it reasonably small.\n",
    "- For MNIST classification with `nn.CrossEntropyLoss()`, the model should output **raw scores** (logits) of shape `(batch, 10)` and you should **not** apply softmax in the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebae06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        # TODO: define layers\n",
    "        self.layers = nn.Sequential(\n",
    "            # nn.Linear(..., ...),\n",
    "            # nn.ReLU(),\n",
    "            # ...\n",
    "            # nn.Linear(..., 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.layers(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork()\n",
    "model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee1b34f",
   "metadata": {},
   "source": [
    "### B4) Loss + optimizer\n",
    "\n",
    "Use `nn.CrossEntropyLoss()`.\n",
    "\n",
    "Pick an optimizer (SGD or Adam) and a learning rate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09cd611",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# TODO: choose optimizer\n",
    "optimizer = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85a4f46",
   "metadata": {},
   "source": [
    "### B5) Training and testing loops\n",
    "\n",
    "Fill in `train()` and `test()`.\n",
    "\n",
    "Hints:\n",
    "- `model.train()` during training, `model.eval()` during testing.\n",
    "- Wrap testing in `torch.no_grad()`.\n",
    "- Accuracy: compare `pred.argmax(1)` to labels `y`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e4999b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    model.train()\n",
    "    for X, y in dataloader:\n",
    "        # TODO: forward pass\n",
    "        pred = None\n",
    "\n",
    "        # TODO: compute loss\n",
    "        loss = None\n",
    "\n",
    "        # TODO: backprop + step\n",
    "        optimizer.zero_grad()\n",
    "        # loss.backward()\n",
    "        # optimizer.step()\n",
    "\n",
    "    # Optional: print last loss\n",
    "    # print(\"train loss:\", float(loss))\n",
    "\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    num_examples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            # TODO: forward pass\n",
    "            pred = None\n",
    "\n",
    "            # TODO: accumulate loss\n",
    "            # test_loss += ...\n",
    "\n",
    "            # TODO: accumulate accuracy counts\n",
    "            # correct += ...\n",
    "            # num_examples += ...\n",
    "\n",
    "    # TODO: compute average loss and accuracy\n",
    "    avg_loss = None\n",
    "    accuracy = None\n",
    "\n",
    "    print(f\"Test accuracy: {accuracy}\")\n",
    "    print(f\"Test avg loss: {avg_loss}\")\n",
    "    return accuracy, avg_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2755c877",
   "metadata": {},
   "source": [
    "### B6) Train until you reach at least 91% test accuracy\n",
    "\n",
    "Tune:\n",
    "- model size\n",
    "- learning rate\n",
    "- optimizer choice\n",
    "- number of epochs\n",
    "- batch size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908c560c",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = None  # TODO\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1}\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cd1ba4",
   "metadata": {},
   "source": [
    "**Short answers (write in markdown below):**\n",
    "1. What final test accuracy did you achieve?\n",
    "2. What settings did you use (batch size, epochs, optimizer, learning rate, model layers)?\n",
    "3. What change had the biggest impact on accuracy?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
