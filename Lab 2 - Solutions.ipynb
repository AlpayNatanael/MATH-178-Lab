{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "d6bcdb1c35cd4fc6a6259d873294603f",
    "deepnote_app_block_visible": false,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "# Lab 2 - Math 178, Spring 2024\n",
    "\n",
    "You are encouraged to work in groups of up to 3 total students, but each student should submit their own file. (It's fine for everyone in the group to submit the same link.)\n",
    "\n",
    "Put the full names of everyone in your group (even if you're working alone) here. This makes grading easier.\n",
    "\n",
    "**Names**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "4808bba5a3234997b2e47e9c23c119b9",
    "deepnote_app_block_visible": false,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "The attached data is a very slightly altered form of this [Kaggle dataset](https://www.kaggle.com/datasets/dhanushnarayananr/credit-card-fraud/data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "db528a2ffc414684a7f44c4fff563108",
    "deepnote_app_block_visible": false,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "* Read in the attached credit card fraud data and look at its contents.  Pay particular attention to the column data types.  In this lab, we are interested in predicting the contents of the \"fraud\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "cf569ebcf40b480581fcc234df2ee816",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1198,
    "execution_start": 1713212655626,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "from pandas.api.types import is_bool_dtype\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "68eedce5c52c4719aaa459722024933d",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1825,
    "execution_start": 1713212687272,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"card_fraud.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "e2278c689b1f439f94b26a7001366b2b",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 343,
    "execution_start": 1713212689979,
    "source_hash": null
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "distance_from_home                float64\n",
       "distance_from_last_transaction    float64\n",
       "ratio_to_median_purchase_price    float64\n",
       "repeat_retailer                      bool\n",
       "used_chip                            bool\n",
       "used_pin_number                      bool\n",
       "online_order                         bool\n",
       "fraud                              object\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "9e12f3c5485f41c78045a8feec1ca78f",
    "deepnote_app_block_visible": false,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Preparing the data\n",
    "\n",
    "Divide the data into a training set and a test set.  Specify a `random_state` when you call `train_test_split`, so that you get consistent results.  I had trouble in the logistic regression section if my training set was too big, so I recommend using only 10% of the data (still a lot, 100,000 rows) as the training size.  It's possible that using even a smaller training size is appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "f53b91ceec4740eb9c7337b7fa4bf2a3",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 89,
    "execution_start": 1713212698989,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(\"fraud\", axis=1), df[\"fraud\"], train_size=10**5, random_state=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "072ad70ae961488db46b66d2795731b1",
    "deepnote_app_block_visible": false,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "* Imagine we always predict \"Not Fraud\".  What accuracy score (i.e., proportion correctly classified) do we get on the training set?  On the test set?  Why can there not be any overfitting here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": "92fae3b83d4746afb859241cb34bb810",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 208,
    "execution_start": 1713212705031,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "y_baseline = np.full_like(y_train, \"Not Fraud\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": "6d0ec5fdc21e4362a7714748b4164147",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 203,
    "execution_start": 1713212706927,
    "source_hash": null
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91352"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = accuracy_score(y_baseline, y_train)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": "bc9b8618b48c47358913b487ec79c04b",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1933,
    "execution_start": 1713212811188,
    "source_hash": null
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9124944444444445"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(np.full_like(y_test, \"Not Fraud\"), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": "5015ca20f80c464bbe861224db3571de",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 179,
    "execution_start": 1713212865836,
    "source_hash": null
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9124944444444445"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_test == \"Not Fraud\").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "3fbd0ab14f934dcf998e9f11923c0459",
    "deepnote_app_block_visible": false,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Logistic regression - using scikit-learn\n",
    "\n",
    "Fit a scikit-learn `LogisticRegression` classification model to the training data.  Because it is such a large dataset, I ran into errors/warnings during the `fit` stage if I had instantiated the `LogisticRegression` object using the default parameters.   To combat this, I used only 10% of the data in my training set, I increased the default number of iterations, and I changed the solver.  You can see the options in the `LogisticRegression` class [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html).  Originally I also increased the default tolerance, but it seems like this makes the model less accurate, so try to avoid increasing the tolerance if possible.  Don't be surprised if fitting the model takes up to 5 minutes.  If you're having issues, try increasing the tolerance very slightly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_id": "bcc0e165ec2347439fed926be0efbdfe",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 312,
    "execution_start": 1713198977240,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "clf = LogisticRegression(tol=0.001, solver=\"sag\", max_iter=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_id": "67d48abaa56f443697363e7cd76cbe8c",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 380,
    "execution_start": 1713212876274,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "clf = LogisticRegression(solver=\"sag\", max_iter=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_id": "e60cd014d52b48c6a55f82eec41f1be7",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 164179,
    "execution_start": 1713212878381,
    "source_hash": null
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=10000, solver=&#x27;sag&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(max_iter=10000, solver=&#x27;sag&#x27;)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=10000, solver='sag')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "9b3748f08e0349bcb8e1d006db797b37",
    "deepnote_app_block_visible": false,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "* What is the accuracy score on the training set?  On the test set?  Are you concerned about overfitting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_id": "8d5491c72488431a82d9b708d7a75294",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 520,
    "execution_start": 1713213190896,
    "source_hash": null
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93907"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cell_id": "29dc6ad10a3c4b87b6371a408b5b2073",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 6004,
    "execution_start": 1713213198571,
    "source_hash": null
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9381833333333334"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "20a90b90d2aa41b3aa5d12b57c0f6304",
    "deepnote_app_block_visible": false,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "* Evaluate the scikit-learn `confusion_matrix` function on the test data ([documentation](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)).  Which entry in this confusion matrix would you focus the most on, if you were a bank?  Why? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cell_id": "5d9b3d443bf14cfb9c0a5aa1b170978d",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 11272,
    "execution_start": 1713213369882,
    "source_hash": null
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 31559,  47196],\n",
       "       [  8439, 812806]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, predictions, labels=clf.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=clf.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7aeea88f8080>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlAAAAGwCAYAAABmTltaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/P9b71AAAACXBIWXMAAA9hAAAPYQGoP6dpAABl60lEQVR4nO3de1xVVf7/8dfhdkSEI4qAR0lNkzQsSxtF5xuWFyxvXWasoUhGIxssIzQbayqzxEuKppY11ohjNo6/MZomizArHVO8kDSipl28YIJYIShyZ//+IHYdMeQIYh3fzx778fDs/Tlrr03A+bA+a69tMQzDQERERETqze1id0BERETk10YJlIiIiIiTlECJiIiIOEkJlIiIiIiTlECJiIiIOEkJlIiIiIiTlECJiIiIOMnjYndA6qeqqoqjR4/i6+uLxWK52N0REREnGYbByZMnsdvtuLldmPGLkpISysrKGqUtLy8vmjVr1ihtuSIlUL8SR48eJSQk5GJ3Q0REGig7O5v27ds3erslJSV06tCC3LzKRmkvODiYAwcOKIn6GUqgfiV8fX0BuMH7Djwsnhe5NyIXhsVqvdhdELlgKowyNpz4h/n7vLGVlZWRm1fJoYyO+Pk2bISr8GQVHXodpKysTAnUz1AC9StRU7bzsHjiYfG6yL0RuTAs+t6WS8CFnobRwtdCC9+GnaMK595fUVHBtGnTWLlyJbm5ubRt25aYmBj+8pe/mOVKwzB45pln+Otf/0p+fj59+vThxRdf5KqrrjLbKS0tZfLkyfzjH/+guLiYgQMH8tJLLzmM2OXn5zNx4kTefvttAEaOHMmiRYto2bKlGXP48GEmTJjAhx9+iLe3N1FRUcydOxcvrx9/x+zatYsHH3yQbdu20apVK8aPH8+TTz5Z7/8/mkQuIiLiQiqNqkbZnDF79mxefvllFi9ezN69e5kzZw7PP/88ixYtMmPmzJlDUlISixcvZvv27QQHBzN48GBOnjxpxsTHx5OSksKqVavYtGkTp06dYvjw4VRW/liWjIqKIjMzk9TUVFJTU8nMzCQ6OvrH66+sZNiwYRQVFbFp0yZWrVrFmjVrmDRpkhlTWFjI4MGDsdvtbN++nUWLFjF37lySkpLqfc0WPUz416GwsBCbzcZNze/SCJS4LJXwxJVVGGWsz19OQUEBfn5+jd5+zedE7r7LGqWEFxx6uN59HT58OEFBQbz22mvmvjvuuIPmzZuzYsUKDMPAbrcTHx/PY489BlSPNgUFBTF79mzGjx9PQUEBbdq0YcWKFdx5553Aj/N/3333XSIjI9m7dy/du3cnPT2dPn36AJCenk54eDiff/45oaGhvPfeewwfPpzs7GzsdjsAq1atIiYmhry8PPz8/FiyZAlTp07l2LFjWH/4vTNr1iwWLVrEkSNH6jUKpREoEREROavCwkKHrbS09Kxxv/3tb1m/fj379+8H4LPPPmPTpk3ccsstABw4cIDc3FyGDBlivsdqtRIREcHmzZsByMjIoLy83CHGbrcTFhZmxmzZsgWbzWYmTwB9+/bFZrM5xISFhZnJE0BkZCSlpaVkZGSYMREREWbyVBNz9OhRDh48WK+vjRIoERERF1LVSP8BhISEYLPZzG3mzJlnPedjjz3GH/7wB6688ko8PT259tpriY+P5w9/+AMAubm5AAQFBTm8LygoyDyWm5uLl5cX/v7+dcYEBgbWOn9gYKBDzJnn8ff3x8vLq86Ymtc1MeeiSeQiIiIupNIwqGzg7Jya92dnZzuU8Kw/U2b/5z//yeuvv84bb7zBVVddRWZmJvHx8djtdsaMGWPGnVkaMwzjnOWyM2POFt8YMTUzmuo7iVwJlIiIiJyVn59fveZAPfroo/z5z3/mrrvuAqBHjx4cOnSImTNnMmbMGIKDgwHMO/Rq5OXlmSM/wcHBlJWVkZ+f7zAKlZeXR79+/cyYY8eO1Tr/8ePHHdrZunWrw/H8/HzKy8sdYs4cacrLywNqj5L9HJXwREREXEgVRqNszjh9+nSt1dXd3d2pqqouBXbq1Ing4GDWrVtnHi8rK2PDhg1mctSrVy88PT0dYnJycsjKyjJjwsPDKSgoYNu2bWbM1q1bKSgocIjJysoiJyfHjElLS8NqtdKrVy8zZuPGjQ6rtqelpWG32+nYsWO9rlkJlIiIiAupwqCygZuzCdSIESOYMWMGa9eu5eDBg6SkpJCUlMRtt90GVJfF4uPjSUxMJCUlhaysLGJiYmjevDlRUVEA2Gw2xo0bx6RJk1i/fj07d+7knnvuoUePHgwaNAiAbt26MXToUGJjY0lPTyc9PZ3Y2FiGDx9OaGgoAEOGDKF79+5ER0ezc+dO1q9fz+TJk4mNjTVH06KiorBarcTExJCVlUVKSgqJiYkkJCSohCciIiJNY9GiRTz55JPExcWRl5eH3W5n/PjxPPXUU2bMlClTKC4uJi4uzlxIMy0tzWFl9vnz5+Ph4cHo0aPNhTSTk5Nxd3c3Y1auXMnEiRPNu/VGjhzJ4sWLzePu7u6sXbuWuLg4+vfv77CQZg2bzca6deuYMGECvXv3xt/fn4SEBBISEup9zVoH6ldC60DJpUDrQIkra6p1oL76PBjfBq4DdfJkFZ2vzL1gfXUFGoESERFxIY15F578PM2BEhEREXGSRqBERERcSNUPW0PbkLopgRIREXEhNXfSNbQNqZsSKBERERdSaVRvDW1D6qY5UCIiIiJO0giUiIiIC9EcqKahBEpERMSFVGGhkvqtpl1XG1I3lfBEREREnKQRKBERERdSZVRvDW1D6qYESkRExIVUNkIJr6HvvxSohCciIiLiJI1AiYiIuBCNQDUNJVAiIiIupMqwUGU08C68Br7/UqASnoiIiIiTNAIlIiLiQlTCaxpKoERERFxIJW5UNrDAVNlIfXFlSqBERERciNEIc6AMzYE6J82BEhEREXGSRqBERERciOZANQ0lUCIiIi6k0nCj0mjgHCg9yuWcVMITERERcZJGoERERFxIFRaqGjg+UoWGoM5FCZSIiIgL0RyopqESnoiIiIiTNAIlIiLiQhpnErlKeOeiBEpERMSFVM+BauDDhFXCOyeV8EREREScpBEoERERF1LVCM/C011456YESkRExIVoDlTTUAIlIiLiQqpw0zpQTUBzoEREREScpBEoERERF1JpWKg0GriQZgPffylQAiUiIuJCKhthEnmlSnjnpBKeiIiIiJOUQImIiLiQKsOtUTZndOzYEYvFUmubMGECAIZhMG3aNOx2O97e3gwYMIDdu3c7tFFaWspDDz1EQEAAPj4+jBw5kiNHjjjE5OfnEx0djc1mw2azER0dzYkTJxxiDh8+zIgRI/Dx8SEgIICJEydSVlbmELNr1y4iIiLw9vamXbt2TJ8+HcPJOw+VQImIiLiQmhJeQzdnbN++nZycHHNbt24dAL///e8BmDNnDklJSSxevJjt27cTHBzM4MGDOXnypNlGfHw8KSkprFq1ik2bNnHq1CmGDx9OZWWlGRMVFUVmZiapqamkpqaSmZlJdHT0j9deWcmwYcMoKipi06ZNrFq1ijVr1jBp0iQzprCwkMGDB2O329m+fTuLFi1i7ty5JCUlOXXNFsPZlEsuisLCQmw2Gzc1vwsPi9fF7o7IBWGxWi92F0QumAqjjPX5yykoKMDPz6/R26/5nFj6aS+a+7o3qK3TJyuJvS7jvPsaHx/PO++8wxdffAGA3W4nPj6exx57DKgebQoKCmL27NmMHz+egoIC2rRpw4oVK7jzzjsBOHr0KCEhIbz77rtERkayd+9eunfvTnp6On369AEgPT2d8PBwPv/8c0JDQ3nvvfcYPnw42dnZ2O12AFatWkVMTAx5eXn4+fmxZMkSpk6dyrFjx7D+8Dtn1qxZLFq0iCNHjmCx1G8CvUagREREXEgVP96Jd75b1Q9tFRYWOmylpaXnPH9ZWRmvv/46Y8eOxWKxcODAAXJzcxkyZIgZY7VaiYiIYPPmzQBkZGRQXl7uEGO32wkLCzNjtmzZgs1mM5MngL59+2Kz2RxiwsLCzOQJIDIyktLSUjIyMsyYiIgIM3mqiTl69CgHDx6s99dZCZSIiIgLqVlIs6EbQEhIiDnfyGazMXPmzHOe/6233uLEiRPExMQAkJubC0BQUJBDXFBQkHksNzcXLy8v/P3964wJDAysdb7AwECHmDPP4+/vj5eXV50xNa9rYupDyxiIiIjIWWVnZzuU8Kz1KLO/9tpr3HzzzQ6jQECt0phhGOcsl50Zc7b4xoipmc1U3/IdaARKRETEpdQ8C6+hG4Cfn5/Ddq4E6tChQ3zwwQfcd9995r7g4GCg9uhOXl6eOfITHBxMWVkZ+fn5dcYcO3as1jmPHz/uEHPmefLz8ykvL68zJi8vD6g9SlYXJVAiIiIupApLo2znY9myZQQGBjJs2DBzX6dOnQgODjbvzIPqeVIbNmygX79+APTq1QtPT0+HmJycHLKyssyY8PBwCgoK2LZtmxmzdetWCgoKHGKysrLIyckxY9LS0rBarfTq1cuM2bhxo8PSBmlpadjtdjp27Fjva1UCJSIi4kIacwTKGVVVVSxbtowxY8bg4fHjDCGLxUJ8fDyJiYmkpKSQlZVFTEwMzZs3JyoqCgCbzca4ceOYNGkS69evZ+fOndxzzz306NGDQYMGAdCtWzeGDh1KbGws6enppKenExsby/DhwwkNDQVgyJAhdO/enejoaHbu3Mn69euZPHkysbGxZikyKioKq9VKTEwMWVlZpKSkkJiYSEJCglMlPM2BEhERkQb74IMPOHz4MGPHjq11bMqUKRQXFxMXF0d+fj59+vQhLS0NX19fM2b+/Pl4eHgwevRoiouLGThwIMnJybi7/7gkw8qVK5k4caJ5t97IkSNZvHixedzd3Z21a9cSFxdH//798fb2Jioqirlz55oxNpuNdevWMWHCBHr37o2/vz8JCQkkJCQ4db1aB+pXQutAyaVA60CJK2uqdaDm7vgt3i0aNj5SfKqCyb03XbC+ugKNQImIiLiQKsNClXF+c5h+2obUTXOgRERERJykESgREREXUnUez7I7WxtSNyVQIiIiLqTKcKPqPO6iO7MNqZu+QiIiIiJO0giUiIiIC6nEQuV5LoT50zakbkqgREREXIhKeE1DXyERERERJ2kESkRExIVU0vASXGXjdMWlKYESERFxISrhNQ0lUCIiIi7kfB8GfGYbUjd9hUREREScpBEoERERF2JgoaqBc6AMLWNwTkqgREREXIhKeE1DXyERERERJ2kESkRExIVUGRaqjIaV4Br6/kuBEigREREXUokblQ0sMDX0/ZcCfYVEREREnKQRKBEREReiEl7TUAIlIiLiQqpwo6qBBaaGvv9SoK+QiIiIiJM0AiUiIuJCKg0LlQ0swTX0/ZcCJVAiIiIuRHOgmoYSKBERERdiGG5UNXAlcUMrkZ+TvkIiIiIiTtIIlIiIiAupxEJlAx8G3ND3XwqUQImIiLiQKqPhc5iqjEbqjAtTCU9ERETESRqBEpcwLCqXYVHHCGpfCsChL7x5Y1F7dmz0B6DfkO+45Q/H6HJVEbZWFUwYcTVf7/VxaGP2yt1c3afQYd+Gd1ozK76r+Tr540/Nc9RY/YqdZc93MF/3DC8g+pHDdOx6mpLT7qxPaUNy0mVUVWpIXBrP6PsOEfPIAd5a0Y6/zroCgHd3f3zW2NfmXs6aZZcBMPT3RxlwyzG6dD9F8xaV/L5vf4pOejrEd+52krEJX3NFWCFVVRY+WdeGpXM6U3La8SNj0K053HbvEdp1PM2pkx58ktaGJTO6IhdXVSNMIm/o+y8FSqAukpiYGE6cOMFbb711sbviEr7N9WLZ85dx9FAzAAbdfpynXt7Hg6Ou5vAXzWnWvIo9Gb78973WxCd+/bPtvLcqkBULQszXpSW1f4n8fX4Iqf8MNF8Xn3Y3/90xtIjpr+1l1UvtmPtoFwKCynhw+gHc3A1endWxEa5UBK4IK2To73P4ep/jHwF3R4Q7vO792+95+Nl9fLKujbnP2qySjE9akfFJK/74yIFabbdqU0ria5+x8b1AXppxBc1bVDD+z1+SMONzEh8JM+NuG5PNbWOy+du8znz+Pz+8vKoIDilu5CuV81GFhaoGzmFq6PsvBZdcAhUTE8Py5ctr7f/iiy/o0qXLReiRNIatH7ZyeL086TKGReVyZc+THP6iOR++Vf0BEtiupM52SovdyP/Wq86Y4iL3n42JGP4dBz5vzhuLq5OwnEPeJM+9jMcW7GflohCKi9zP+j6R+mrWvIIps/ey8Omu3DX+kMOx/G+tDq/73vQt/9vWktwj3ua+f6+o/t7scX3+Wdv/zYDvqCi38NJzV2D8MI/mpeeuYPGaDNpedpqcw81p4VdO9EMHeGZCDz7b6m++9/BXPmdtU8QVXZJjdEOHDiUnJ8dh69Spk0NMWVnZReqdNJSbm0HEsG9p1ryKz3f6OvXeG0d9y6pt23n5vUzu+/NBvH0qa8X8/v5v+Of27Sx++zPu+tMRPDyrzGOeXlWUlTr+WJWWumFtZtAl7NT5XZDIT8T95Qu2bWxNZnqrOuNati7j+hu+J+3Ntk617+lZRUW5m5k8AZSWVCf+V11XAMC14fm4uRm0Dirl5be38ff1m5k6bzcBwXX/gSJNo2Yl8oZuUrdLMoGyWq0EBwc7bAMHDuTBBx8kISGBgIAABg8eDEBSUhI9evTAx8eHkJAQ4uLiOHXqxw/CadOm0bNnT4f2FyxYQMeOHc3XlZWVJCQk0LJlS1q3bs2UKVMwDN3i0Ng6di3izc+28vaedB589mue/VMoh79sXu/3f/R2ALPir+Cxu6/iH4vb0z/ye/7y4j6HmLeWB1fH3NOd/7wezK1/zGHCMz+WQT79b0u6XXeSiOHfmh8wf4g7AkCrNuWNc6Fyybrh5mN06XaK5Pmdzhk7aFQuxafd+WRdgFPn+GyrP/4BZdzxx8N4eFbRwq+cmPjqsnergOo/LINDirG4wZ2xh/jr7C7MeOQqWtjKmbH0M4c/KOTiqJkD1dBN6qav0E8sX74cDw8PPvnkE1555RUA3NzcWLhwIVlZWSxfvpwPP/yQKVOmONXuvHnz+Nvf/sZrr73Gpk2b+P7770lJSanzPaWlpRQWFjpsUrcjB7yZMPJqHvldD9a+EcSk57/ksi6n6/3+1H8Gkbm5JYe+aM6GtQHMeLAr1/22gM5X/Zgwv7XMzq5tNg7u8+H91UEsevJyho7Ow7dldXL06aaWvDa7Aw89+zVv70nn1XWZbPu4usRRpc8VaYCA4BLG//lLnv9zN8rLzl0KHnxbDh+9E1Sv2J86/JUPSU9cyW0x2aTs2MjKDZvJyfbm+289qaqqHpWwWMDT0+DlmVfw6Set2Pc/G7Mf7Y69QzFX/+bE+VyeyK/OJTcHCuCdd96hRYsW5uubb74ZgC5dujBnzhyH2Pj4ePPfnTp14tlnn+VPf/oTL730Ur3Pt2DBAqZOncodd9wBwMsvv8z7779f53tmzpzJM888U+9zCFSUu5FzqHquxxdZLejao4hRY3JY9GTn82rvy90+lJdZaNehhK92tzhrzOeZ1fvtHUrYd6L6TqaUv9lJ+VtbWgWWc6rAnaD2pYx99DDHspudVz9EAK7ofhL/gHIWrt5h7nP3gLDeBYz4wzeMujbCTHCuuu4EIZcXM2uyc+W7Gh+vDeLjtUG0bF1GSXF1Oe+2MdnkHqn+Hs4/Xj0H8PBXP47wFuZ7UZjvSZu2KuNdbFU0wrPwNIn8nC7JEagbb7yRzMxMc1u4cCEAvXv3rhX70UcfMXjwYNq1a4evry/33nsv3333HUVFRfU6V0FBATk5OYSH/3h3jIeHx1nP9VNTp06loKDA3LKzs524QgGwWAw8vc6/VNrhimI8vQy+P/7zk8o7d68e4fo+78wYC9/neVFW6s6A4d+Sd9SLL3drgq2cv8x0f/40qjcP3vHjtj/Ll4/fCeLBO3qbyRPAkDty+CKrBQf2nT3xr68T33lRctqDG4bmUV7qxs4t1aOpe3baAGjf8ce77lrYyvHzLyfvqP5QuNiMH+7Ca8hmnEcC9c0333DPPffQunVrmjdvTs+ePcnIyPixX4bBtGnTsNvteHt7M2DAAHbv3u3QRmlpKQ899BABAQH4+PgwcuRIjhw54hCTn59PdHQ0NpsNm81GdHQ0J06ccIg5fPgwI0aMwMfHh4CAACZOnFhrbvOuXbuIiIjA29ubdu3aMX36dKem11ySI1A+Pj5nvePOx8fxA+7QoUPccsstPPDAAzz77LO0atWKTZs2MW7cOMrLq0s2bm5utb7gNccawmq1YrVazx0oAIyZdJgdG1pyPMeL5j6VRAz/jh59CnlybDeg+pd7oL2M1oHVP0DtO1X/4s8/7kn+t160vayEG0ceZ/vH/hTke9ChSzH3TT3El7t92JNRPRH9ymtPcmXPk/wv3UbRSXe6Xn2K+x8/yJYP/Dme8+P/qzvu+4aMjS2pMiz0H/I9vx9/lJkTuzp8wIk4q/i0B4e+dEyISk67UVjguN/bp4L/G3KcV58/+8irf0Ap/gFl2C+r/hnoeEURxafdyctpxqmC6lHU4VFH2LvTRslpd67tl8/YSV+RPP9yc72obw41Z8v61oyf+gWLpoVy+pQ7MY8c4MiB5vxvW8sLcPXijCqjEUagnHx/fn4+/fv358Ybb+S9994jMDCQr776ipYtW5oxc+bMISkpieTkZLp27cpzzz3H4MGD2bdvH76+1b9n4+Pj+c9//sOqVato3bo1kyZNYvjw4WRkZODuXl2OjoqK4siRI6SmpgJw//33Ex0dzX/+8x+get7xsGHDaNOmDZs2beK7775jzJgxGIbBokWLACgsLGTw4MHceOONbN++nf379xMTE4OPjw+TJk2q1zVfkglUfe3YsYOKigrmzZuHm1v1YN3q1asdYtq0aUNubi6GYWCxVH/DZWZmmsdtNhtt27YlPT2dG264AYCKigoyMjK47rrrmuZCLgH+AWU8OvdLWgWWUXTSnQOf+/Dk2G7s/KQlAH0H5jNpzldm/NSFXwDw+sL2rFwYQnm5hZ79Chg1Jhdvn0qO53ix7SN/Vi5qbyY+5WUWIoZ9x90PHcHTq4q8b6ykrg7iX3+1O/Sld8QJ7or7Bk+vKg587sP0B0LNBT1FLrSIW/LAAh+/G3TW47eMPsrdE35c/uD5FZkAJD0RygdvVZf8QsNOcs+Eg3g3ryT7QHMWP9OVD/8T7NDO3KnduP+xL5n20i4MA3Ztb8mT46+msuKSLGxc8mbPnk1ISAjLli0z9/30ZirDMFiwYAFPPPEEt99+O1A97zgoKIg33niD8ePHU1BQwGuvvcaKFSsYNGgQAK+//johISF88MEHREZGsnfvXlJTU0lPT6dPnz4ALF26lPDwcPbt20doaChpaWns2bOH7Oxs7Pbq38/z5s0jJiaGGTNm4Ofnx8qVKykpKSE5ORmr1UpYWBj79+8nKSmJhIQE8/O8Lkqg6tC5c2cqKipYtGgRI0aM4JNPPuHll192iBkwYADHjx9nzpw5/O53vyM1NZX33nsPPz8/M+bhhx9m1qxZXHHFFXTr1o2kpKRaw43SMAum1r2G1wdvBvLBm4E/e/zbHCtTosJ+9jjAV7tb8MjvepyzL1OjrzpnjEhj+PMfr621L/X/2Un9f/azRFdb+VInVr5U91188x7vds5zFxd58MJTV/LCU+fupzStxlyJ/MwbmH6uOvL2228TGRnJ73//ezZs2EC7du2Ii4sjNjYWgAMHDpCbm8uQIUMc2oqIiGDz5s2MHz+ejIwMysvLHWLsdjthYWFs3ryZyMhItmzZgs1mM5MngL59+2Kz2di8eTOhoaFs2bKFsLAwM3kCiIyMpLS0lIyMDG688Ua2bNlCRESEw7VERkYydepUDh48WGtpo7PRnwp16NmzJ0lJScyePZuwsDBWrlzJzJkzHWK6devGSy+9xIsvvsg111zDtm3bmDx5skPMpEmTuPfee4mJiSE8PBxfX19uu+22prwUERG5RNSU8Bq6AYSEhJhzjWw2W63PwBpff/01S5Ys4YorruD999/ngQceYOLEifz9738HIDc3F4CgIMeR0aCgIPNYbm4uXl5e+Pv71xkTGFj7j+HAwECHmDPP4+/vj5eXV50xNa9rYs7lkhuBSk5OPuv+jz/++Kz7H3nkER555BGHfdHR0Q6vH3jgAR544AGHfY8//rj5bw8PDxYsWMCCBQuc7q+IiMjFkp2d7VBR+bm5uVVVVfTu3ZvExEQArr32Wnbv3s2SJUu49957zbgzS2M/nf7yc86MOVt8Y8TUzGeuT/kONAIlIiLiUhp6B95Pn6Xn5+fnsP1cAtW2bVu6d+/usK9bt24cPnwYgODg6jl0Z47u5OXlmSM/wcHBlJWVkZ+fX2fMsWPHap3/+PHjDjFnnic/P5/y8vI6Y/Ly8oDao2Q/RwmUiIiIC2nMEl599e/fn337HJ/csH//fjp06ABUr6MYHBzMunXrzONlZWVs2LCBfv36AdCrVy88PT0dYnJycsjKyjJjwsPDKSgoYNu2bWbM1q1bKSgocIjJysoiJyfHjElLS8NqtdKrVy8zZuPGjQ5LG6SlpWG32x0mv9dFCZSIiIg0yCOPPEJ6ejqJiYl8+eWXvPHGG/z1r39lwoQJQHVZLD4+nsTERFJSUsjKyiImJobmzZsTFRUFVN+1Pm7cOCZNmsT69evZuXMn99xzDz169DDvyuvWrRtDhw4lNjaW9PR00tPTiY2NZfjw4YSGhgIwZMgQunfvTnR0NDt37mT9+vVMnjyZ2NhYsxwZFRWF1WolJiaGrKwsUlJSSExMrPcdeHAJzoESERFxZRdjHajrr7+elJQUpk6dyvTp0+nUqRMLFizg7rvvNmOmTJlCcXExcXFx5Ofn06dPH9LS0sw1oADmz5+Ph4cHo0ePpri4mIEDB5KcnGyuAQWwcuVKJk6caN6tN3LkSBYvXmwed3d3Z+3atcTFxdG/f3+8vb2Jiopi7ty5ZozNZmPdunVMmDCB3r174+/vT0JCAgkJCfW+Zouhp9r+KhQWFmKz2bip+V14WH5+ZWyRXzOLFo8VF1ZhlLE+fzkFBQUOE7MbS83nROR79+Pp07DPifKiMt6/+a8XrK+uQCU8ERERESephCciIuJCLkYJ71KkBEpERMSFGGAuQ9CQNqRuSqBERERciEagmobmQImIiIg4SSNQIiIiLkQjUE1DCZSIiIgLUQLVNFTCExEREXGSRqBERERciEagmoYSKBERERdiGBaMBiZADX3/pUAlPBEREREnaQRKRETEhVRhafBCmg19/6VACZSIiIgL0RyopqESnoiIiIiTNAIlIiLiQjSJvGkogRIREXEhKuE1DSVQIiIiLkQjUE1Dc6BEREREnKQRKBERERdiNEIJTyNQ56YESkRExIUYgGE0vA2pm0p4IiIiIk7SCJSIiIgLqcKCRSuRX3BKoERERFyI7sJrGirhiYiIiDhJI1AiIiIupMqwYNFCmhecEigREREXYhiNcBeebsM7J5XwRERERJykESgREREXoknkTUMJlIiIiAtRAtU0lECJiIi4EE0ibxqaAyUiIiLiJI1AiYiIuBDdhdc0lECJiIi4kOoEqqFzoBqpMy5MJTwRERERJ2kESkRExIXoLrymoREoERERF2I00uaMadOmYbFYHLbg4OAf+2QYTJs2Dbvdjre3NwMGDGD37t0ObZSWlvLQQw8REBCAj48PI0eO5MiRIw4x+fn5REdHY7PZsNlsREdHc+LECYeYw4cPM2LECHx8fAgICGDixImUlZU5xOzatYuIiAi8vb1p164d06dPx3CybqkESkRERBrsqquuIicnx9x27dplHpszZw5JSUksXryY7du3ExwczODBgzl58qQZEx8fT0pKCqtWrWLTpk2cOnWK4cOHU1lZacZERUWRmZlJamoqqampZGZmEh0dbR6vrKxk2LBhFBUVsWnTJlatWsWaNWuYNGmSGVNYWMjgwYOx2+1s376dRYsWMXfuXJKSkpy6XpXwREREXMjFKuF5eHg4jDr92JbBggULeOKJJ7j99tsBWL58OUFBQbzxxhuMHz+egoICXnvtNVasWMGgQYMAeP311wkJCeGDDz4gMjKSvXv3kpqaSnp6On369AFg6dKlhIeHs2/fPkJDQ0lLS2PPnj1kZ2djt9sBmDdvHjExMcyYMQM/Pz9WrlxJSUkJycnJWK1WwsLC2L9/P0lJSSQkJGCx1O/aNQIlIiLiShqxhldYWOiwlZaW/uxpv/jiC+x2O506deKuu+7i66+/BuDAgQPk5uYyZMgQM9ZqtRIREcHmzZsByMjIoLy83CHGbrcTFhZmxmzZsgWbzWYmTwB9+/bFZrM5xISFhZnJE0BkZCSlpaVkZGSYMREREVitVoeYo0ePcvDgwXp8gaspgRIREXElP4xANWTjhxGokJAQc76RzWZj5syZZz1lnz59+Pvf/87777/P0qVLyc3NpV+/fnz33Xfk5uYCEBQU5PCeoKAg81hubi5eXl74+/vXGRMYGFjr3IGBgQ4xZ57H398fLy+vOmNqXtfE1IdKeCIiInJW2dnZ+Pn5ma9/OmrzUzfffLP57x49ehAeHk7nzp1Zvnw5ffv2BahVGjMM45zlsjNjzhbfGDE1E8jrW74DjUCJiIi4lJqVyBu6Afj5+TlsP5dAncnHx4cePXrwxRdfmPOizhzdycvLM0d+goODKSsrIz8/v86YY8eO1TrX8ePHHWLOPE9+fj7l5eV1xuTl5QG1R8nqogRKRETEhTS0fNcYk9BLS0vZu3cvbdu2pVOnTgQHB7Nu3TrzeFlZGRs2bKBfv34A9OrVC09PT4eYnJwcsrKyzJjw8HAKCgrYtm2bGbN161YKCgocYrKyssjJyTFj0tLSsFqt9OrVy4zZuHGjw9IGaWlp2O12OnbsWO9rVAIlIiIiDTJ58mQ2bNjAgQMH2Lp1K7/73e8oLCxkzJgxWCwW4uPjSUxMJCUlhaysLGJiYmjevDlRUVEA2Gw2xo0bx6RJk1i/fj07d+7knnvuoUePHuZded26dWPo0KHExsaSnp5Oeno6sbGxDB8+nNDQUACGDBlC9+7diY6OZufOnaxfv57JkycTGxtrliKjoqKwWq3ExMSQlZVFSkoKiYmJTt2BB5oDJSIi4lp+Mgm8QW044ciRI/zhD3/g22+/pU2bNvTt25f09HQ6dOgAwJQpUyguLiYuLo78/Hz69OlDWloavr6+Zhvz58/Hw8OD0aNHU1xczMCBA0lOTsbd3d2MWblyJRMnTjTv1hs5ciSLFy82j7u7u7N27Vri4uLo378/3t7eREVFMXfuXDPGZrOxbt06JkyYQO/evfH39ychIYGEhASnrtliOLv0plwUhYWF2Gw2bmp+Fx4Wr4vdHZELwlLP+RUiv0YVRhnr85dTUFDgMDG7sdR8TnR49UncmjdrUFtVp0s4dN+zF6yvrkAlPBEREREnqYQnIiLiSs7nYXZna0PqpARKRETEhVysR7lcauqVQC1cuLDeDU6cOPG8OyMiIiLya1CvBGr+/Pn1asxisSiBEhERudhUgrvg6pVAHThw4EL3Q0RERBqBSnhN47zvwisrK2Pfvn1UVFQ0Zn9ERESkIYxG2qROTidQp0+fZty4cTRv3pyrrrqKw4cPA9Vzn2bNmtXoHRQRERH5pXE6gZo6dSqfffYZH3/8Mc2a/bhQ16BBg/jnP//ZqJ0TERERZ1kaaZO6OL2MwVtvvcU///lP+vbt6/DMmO7du/PVV181audERETESVoHqkk4PQJ1/PhxAgMDa+0vKipy6iF8IiIiIr9WTidQ119/PWvXrjVf1yRNS5cuJTw8vPF6JiIiIs7TJPIm4XQJb+bMmQwdOpQ9e/ZQUVHBCy+8wO7du9myZQsbNmy4EH0UERGR+jIs1VtD25A6OT0C1a9fPz755BNOnz5N586dSUtLIygoiC1bttCrV68L0UcRERGRX5TzehZejx49WL58eWP3RURERBrIMKq3hrYhdTuvBKqyspKUlBT27t2LxWKhW7dujBo1Cg8PPZtYRETkotJdeE3C6YwnKyuLUaNGkZubS2hoKAD79++nTZs2vP322/To0aPROykiIiLyS+L0HKj77ruPq666iiNHjvDpp5/y6aefkp2dzdVXX839999/IfooIiIi9VUzibyhm9TJ6RGozz77jB07duDv72/u8/f3Z8aMGVx//fWN2jkRERFxjsWo3hrahtTN6RGo0NBQjh07Vmt/Xl4eXbp0aZROiYiIyHnSOlBNol4JVGFhobklJiYyceJE/vWvf3HkyBGOHDnCv/71L+Lj45k9e/aF7q+IiIjIRVevEl7Lli0dHtNiGAajR4829xk/3O84YsQIKisrL0A3RUREpF60kGaTqFcC9dFHH13ofoiIiEhj0DIGTaJeCVRERMSF7oeIiIjIr8Z5r3x5+vRpDh8+TFlZmcP+q6++usGdEhERkfOkEagm4XQCdfz4cf74xz/y3nvvnfW45kCJiIhcREqgmoTTyxjEx8eTn59Peno63t7epKamsnz5cq644grefvvtC9FHERERkV8Up0egPvzwQ/79739z/fXX4+bmRocOHRg8eDB+fn7MnDmTYcOGXYh+ioiISH3oLrwm4fQIVFFREYGBgQC0atWK48ePA9CjRw8+/fTTxu2diIiIOKVmJfKGblK381qJfN++fQD07NmTV155hW+++YaXX36Ztm3bNnoHRURERH5pnC7hxcfHk5OTA8DTTz9NZGQkK1euxMvLi+Tk5Mbun4iIiDhDk8ibhNMJ1N13323++9prr+XgwYN8/vnnXHbZZQQEBDRq50RERER+ic57HagazZs357rrrmuMvoiIiEgDWWj4HCZNIT+3eiVQCQkJ9W4wKSnpvDsjIiIi8mtQrwRq586d9Wrspw8clguj6nQxVZaKi90NkQvi/S83X+wuiFwwhSer8O/aBCfSMgZNol534X300Uf12j788MML3V8RERGpi9FI23maOXMmFouF+Pj4H7tkGEybNg273Y63tzcDBgxg9+7dDu8rLS3loYceIiAgAB8fH0aOHMmRI0ccYvLz84mOjsZms2Gz2YiOjubEiRMOMYcPH2bEiBH4+PgQEBDAxIkTaz12bteuXURERODt7U27du2YPn06huHcRTu9jIGIiIjI2Wzfvp2//vWvtZ6LO2fOHJKSkli8eDHbt28nODiYwYMHc/LkSTMmPj6elJQUVq1axaZNmzh16hTDhw93eERcVFQUmZmZpKamkpqaSmZmJtHR0ebxyspKhg0bRlFREZs2bWLVqlWsWbOGSZMmmTGFhYUMHjwYu93O9u3bWbRoEXPnznV6ClKDJ5GLiIjIL8hFWsbg1KlT3H333SxdupTnnnvux6YMgwULFvDEE09w++23A7B8+XKCgoJ44403GD9+PAUFBbz22musWLGCQYMGAfD6668TEhLCBx98QGRkJHv37iU1NZX09HT69OkDwNKlSwkPD2ffvn2EhoaSlpbGnj17yM7Oxm63AzBv3jxiYmKYMWMGfn5+rFy5kpKSEpKTk7FarYSFhbF//36SkpJISEio93QkjUCJiIi4kMZcibywsNBhKy0t/dnzTpgwgWHDhpkJUI0DBw6Qm5vLkCFDzH1Wq5WIiAg2b66e95iRkUF5eblDjN1uJywszIzZsmULNpvNTJ4A+vbti81mc4gJCwszkyeAyMhISktLycjIMGMiIiKwWq0OMUePHuXgwYP1/jorgRIREZGzCgkJMecb2Ww2Zs6ceda4VatW8emnn571eG5uLgBBQUEO+4OCgsxjubm5eHl54e/vX2dMzaPkfiowMNAh5szz+Pv74+XlVWdMzeuamPpQCU9ERMSVNGIJLzs7Gz8/P3P3T0dtamRnZ/Pwww+TlpZGs2bNfrbJM0tjhmGcs1x2ZszZ4hsjpmYCuTOrCZzXCNSKFSvo378/drudQ4cOAbBgwQL+/e9/n09zIiIi0lga8S48Pz8/h+1sCVRGRgZ5eXn06tULDw8PPDw82LBhAwsXLsTDw+NnR3fy8vLMY8HBwZSVlZGfn19nzLFjx2qd//jx4w4xZ54nPz+f8vLyOmPy8vKA2qNkdXE6gVqyZAkJCQnccsstnDhxwpwd37JlSxYsWOBscyIiIvIrNnDgQHbt2kVmZqa59e7dm7vvvpvMzEwuv/xygoODWbdunfmesrIyNmzYQL9+/QDo1asXnp6eDjE5OTlkZWWZMeHh4RQUFLBt2zYzZuvWrRQUFDjEZGVlmc/sBUhLS8NqtdKrVy8zZuPGjQ5LG6SlpWG32+nYsWO9r9vpBGrRokUsXbqUJ554And3d3N/79692bVrl7PNiYiISCNqzEnk9eHr60tYWJjD5uPjQ+vWrQkLCzPXhEpMTCQlJYWsrCxiYmJo3rw5UVFRANhsNsaNG8ekSZNYv349O3fu5J577qFHjx7mpPRu3boxdOhQYmNjSU9PJz09ndjYWIYPH05oaCgAQ4YMoXv37kRHR7Nz507Wr1/P5MmTiY2NNUuRUVFRWK1WYmJiyMrKIiUlhcTERKfuwIPzmAN14MABrr322lr7rVYrRUVFzjYnIiIijekXuBL5lClTKC4uJi4ujvz8fPr06UNaWhq+vr5mzPz58/Hw8GD06NEUFxczcOBAkpOTHQZrVq5cycSJE8279UaOHMnixYvN4+7u7qxdu5a4uDj69++Pt7c3UVFRzJ0714yx2WysW7eOCRMm0Lt3b/z9/UlISHDqsXUAFsPJpTe7d+/OzJkzGTVqFL6+vnz22WdcfvnlLFy4kOXLl5u3CUrjKiwsxGazMYBReFg8L3Z3RC6I949mXuwuiFww1Y9y+ZqCggKHidmN1v4PnxOdpiXiVsdk7vqoKinhwLTHL1hfXYHTI1CPPvooEyZMoKSkBMMw2LZtG//4xz+YOXMmr7766oXoo4iIiMgvitMJ1B//+EcqKiqYMmUKp0+fJioqinbt2vHCCy9w1113XYg+ioiISD05O4fp59qQup3XOlCxsbHExsby7bffUlVVddaFrUREROQiuEiPcrnUNGghzYCAgMbqh4iIiMivhtMJVKdOneq8ze/rr79uUIdERESkARqhhKcRqHNzOoGKj493eF1eXs7OnTtJTU3l0Ucfbax+iYiIyPlQCa9JOJ1APfzww2fd/+KLL7Jjx44Gd0hERETkl+68noV3NjfffDNr1qxprOZERETkfDTis/Dk5zVoEvlP/etf/6JVq1aN1ZyIiIicBy1j0DScTqCuvfZah0nkhmGQm5vL8ePHeemllxq1cyIiIiK/RE4nULfeeqvDazc3N9q0acOAAQO48sorG6tfIiIiIr9YTiVQFRUVdOzYkcjISIKDgy9Un0REROR86S68JuHUJHIPDw/+9Kc/UVpaeqH6IyIiIg1QMweqoZvUzem78Pr06cPOnTsvRF9EREREfhWcngMVFxfHpEmTOHLkCL169cLHx8fh+NVXX91onRMREZHzoBGkC67eCdTYsWNZsGABd955JwATJ040j1ksFgzDwGKxUFlZ2fi9FBERkfrRHKgmUe8Eavny5cyaNYsDBw5cyP6IiIiI/OLVO4EyjOp0tEOHDhesMyIiItIwWkizaTg1B+qnC2iKiIjIL5BKeE3CqQSqa9eu50yivv/++wZ1SEREROSXzqkE6plnnsFms12ovoiIiEgDqYTXNJxKoO666y4CAwMvVF9ERESkoVTCaxL1XkhT859EREREqjl9F56IiIj8gmkEqknUO4Gqqqq6kP0QERGRRqA5UE3D6Ue5iIiIyC+YRqCahNMPExYRERG51GkESkRExJVoBKpJKIESERFxIZoD1TRUwhMRERFxkkagREREXIlKeE1CCZSIiIgLUQmvaaiEJyIiIuIkjUCJiIi4EpXwmoQSKBEREVeiBKpJqIQnIiIiDbJkyRKuvvpq/Pz88PPzIzw8nPfee888bhgG06ZNw2634+3tzYABA9i9e7dDG6WlpTz00EMEBATg4+PDyJEjOXLkiENMfn4+0dHR2Gw2bDYb0dHRnDhxwiHm8OHDjBgxAh8fHwICApg4cSJlZWUOMbt27SIiIgJvb2/atWvH9OnTnX7mrxIoERERF2JppM0Z7du3Z9asWezYsYMdO3Zw0003MWrUKDNJmjNnDklJSSxevJjt27cTHBzM4MGDOXnypNlGfHw8KSkprFq1ik2bNnHq1CmGDx9OZWWlGRMVFUVmZiapqamkpqaSmZlJdHS0ebyyspJhw4ZRVFTEpk2bWLVqFWvWrGHSpElmTGFhIYMHD8Zut7N9+3YWLVrE3LlzSUpKcuqaLYazKZdcFIWFhdhsNgYwCg+L58XujsgF8f7RzIvdBZELpvBkFf5dv6agoAA/P7/Gb/+Hz4nuf0rE3dqsQW1VlpawZ8njDeprq1ateP755xk7dix2u534+Hgee+wxoHq0KSgoiNmzZzN+/HgKCgpo06YNK1as4M477wTg6NGjhISE8O677xIZGcnevXvp3r076enp9OnTB4D09HTCw8P5/PPPCQ0N5b333mP48OFkZ2djt9sBWLVqFTExMeTl5eHn58eSJUuYOnUqx44dw2q1AjBr1iwWLVrEkSNHsFjqlz5qBEpERMSF1Cxj0NANqpOyn26lpaXnPH9lZSWrVq2iqKiI8PBwDhw4QG5uLkOGDDFjrFYrERERbN68GYCMjAzKy8sdYux2O2FhYWbMli1bsNlsZvIE0LdvX2w2m0NMWFiYmTwBREZGUlpaSkZGhhkTERFhJk81MUePHuXgwYP1/jorgRIREZGzCgkJMecb2Ww2Zs6c+bOxu3btokWLFlitVh544AFSUlLo3r07ubm5AAQFBTnEBwUFmcdyc3Px8vLC39+/zpjAwMBa5w0MDHSIOfM8/v7+eHl51RlT87ompj50F56IiIgracS78LKzsx1KeD8dtTlTaGgomZmZnDhxgjVr1jBmzBg2bNhgHj+zNGYYxjnLZWfGnC2+MWJqZjPVt3wHGoESERFxPUYDtx/U3FVXs9WVQHl5edGlSxd69+7NzJkzueaaa3jhhRcIDg4Gao/u5OXlmSM/wcHBlJWVkZ+fX2fMsWPHap33+PHjDjFnnic/P5/y8vI6Y/Ly8oDao2R1UQIlIiIijc4wDEpLS+nUqRPBwcGsW7fOPFZWVsaGDRvo168fAL169cLT09MhJicnh6ysLDMmPDycgoICtm3bZsZs3bqVgoICh5isrCxycnLMmLS0NKxWK7169TJjNm7c6LC0QVpaGna7nY4dO9b7+pRAiYiIuJDGnEReX48//jj//e9/OXjwILt27eKJJ57g448/5u6778ZisRAfH09iYiIpKSlkZWURExND8+bNiYqKAsBmszFu3DgmTZrE+vXr2blzJ/fccw89evRg0KBBAHTr1o2hQ4cSGxtLeno66enpxMbGMnz4cEJDQwEYMmQI3bt3Jzo6mp07d7J+/XomT55MbGysWYqMiorCarUSExNDVlYWKSkpJCYmkpCQ4FQJT3OgREREXMlFWIn82LFjREdHk5OTg81m4+qrryY1NZXBgwcDMGXKFIqLi4mLiyM/P58+ffqQlpaGr6+v2cb8+fPx8PBg9OjRFBcXM3DgQJKTk3F3dzdjVq5cycSJE8279UaOHMnixYvN4+7u7qxdu5a4uDj69++Pt7c3UVFRzJ0714yx2WysW7eOCRMm0Lt3b/z9/UlISCAhIcGpa9Y6UL8SWgdKLgVaB0pcWVOtAxUWm4i7VwPXgSorIWtpw9aBcnUagRIREXEh51OCO1sbUjclUCIiIq5EDxNuEppELiIiIuIkjUCJiIi4EJXwmoYSKBEREVeiEl6TUAIlIiLiSpRANQnNgRIRERFxkkagREREXIjmQDUNJVAiIiKuRCW8JqESnoiIiIiTNAIlIiLiQiyGgaWBT2lr6PsvBUqgREREXIlKeE1CJTwRERERJ2kESkRExIXoLrymoQRKRETElaiE1yRUwhMRERFxkkagREREXIhKeE1DCZSIiIgrUQmvSSiBEhERcSEagWoamgMlIiIi4iSNQImIiLgSlfCahBIoERERF6MS3IWnEp6IiIiIkzQCJSIi4koMo3praBtSJyVQIiIiLkR34TUNlfBEREREnKQRKBEREVeiu/CahBIoERERF2Kpqt4a2obUTSU8ERERESdpBEpclpu7QfSkXG66/QT+bcr5Ps+Tdav9eWNBEIZhqRU/cXY2w6K/5+Wn7KS82sZh/7X/d4rWQeUUn3Zj7w4fXpvRluwvm5kxXXqcZtwTOXS95jRVlRY2vWvjlWl2Sk67N8m1iuuprIAV84L58E1/8o970iqwnMGjvycq/hhuP/zpu+ldG++uaM0X/2tOYb4HL6Xto3NYsdlGYb47K+YG8+kGX44f9cKvVQX9hhYwZkoOPn4/DjEc+crK0mft7NnuQ0W5hY5XFjPmsVx69j9lxuQd8WTx4+3J/KQF1mYGN96WT+xTR/H0+rHWYxjwr5fb8N7K1uQd8cLWuoLhY77lDxPzLvwXTH6kEl6TUAJ1EXXs2JH4+Hji4+Mvdldc0p0T8hh273fMffgyDu1rxhXXnGbS/GyKCt1567U2DrHhQwu48rrTfJtT+0fii/8158M3/Tn+jRe+/hXcM+kYif/4mjF9ulFVZaFVUDmzVn3Nhrdb8uIT7WjeoooHpn/D5AXZPHd/xya6WnE1/3wxiLV/D2DyC4fpEFrCF595M++Ry/Dxq+S2+74FoOS0G92vL+L/hp9gwaOX1Wrj+2OefHfMk9injnJZ1xLyjnix8M/t+e6YJ08uPWjGPXnv5bS/vITZ/+9LrM2qSFnahqfu7UTylr20CqygsrI6xta6gqS3vqQw35258ZdhGDBhxjdmO0uebEfGBl9inzxKp24lFBW6U/C9/ohoaroLr2lc1BJeTEwMFouFWbNmOex/6623sFhqjxDUpWPHjixYsKBecRaLxWFr3769U+eSX4duvYrY8r6Nbev9OHbEi01rW/LpBl+uuKbYIa51cDkTnvuG2RM6UFFR+/vuvZWtydragmNHvPhyV3OWzw4msF05QSFlAPQZVEhFhYXFj7fjyFfN2P9ZcxY/3p7/G16AvWNpk1yruJ69Gc0Jjyygz6BCgkPK+L/hBVwXcZIvPmtuxgz6XT73JBzj2htOnbWNjleW8NSrB+k7pBB7xzJ6/vYUMY/lsHWdH5UV1TEF37lz9ICV0Q/mcXn3EtpdXsbYJ3IoLXbn0L7qUdZPN/hyeH8zHlt0iC49irnuhlPc/9RR3nujNUUnqz9GDn9h5Z2/BzBt2QHCIwsJvqyMzmHVsdLEataBaugmdbroc6CaNWvG7Nmzyc/Pb7JzTp8+nZycHHPbuXPnWePKy8ubrE/S+LK2+9Dztydpd3l1EnN592Ku+k0R2z/0NWMsFoMpCw/zryVtOLS/2c81ZbJ6VzLkzu/JOeTF8aOeAHhaq6gotziUBctKqv991W+KGvOS5BISdn0RmZt8OfKVFYCvdjdj9zYfrr+psEHtFhW607xFFe4/DLb6tarksitK+OD/taLktBuVFbB2RWv825RzxdXVf2zs2eFDhytLaB1cYbbTa8BJykvd+OJ/1QldepqNtpeVsvUDP+7t0417f9Od+ZNCKMzXCJS4poueQA0aNIjg4GBmzpxZZ9yaNWu46qqrsFqtdOzYkXnz5pnHBgwYwKFDh3jkkUfMUaW6+Pr6EhwcbG5t2lSXcywWCy+//DKjRo3Cx8eH5557jsrKSsaNG0enTp3w9vYmNDSUF154waG9AQMG1CrD3XrrrcTExJiv8/LyGDFiBN7e3nTq1ImVK1fW2cfS0lIKCwsdNnHO6sWBfPyWP69u/Jy1hz7jxbT9pCwN4OO3/M2Y0RPyqKyEt14LqLOt4WO+5a0vdvH2V1n0vvEkU++6nIry6h+fzzb54t+mnN/9KQ8Pzypa2Cr4459zAWgVqCRczs/oB/MYcGs+991wJbdcdg0ThoRyW+xxbrztxHm3Wfi9O28sCOaW6G/NfRYLzFz1FV9leXPrFT0Y3ukaUpa2YcbKr2lhqwQg/7gH/gGO38u+LSvx9KoiP686E8s57MWxb7z47zsteXThYSYtOMwX//NWGfsiqCnhNXSTul30OVDu7u4kJiYSFRXFxIkTz1pOy8jIYPTo0UybNo0777yTzZs3ExcXR+vWrYmJieHNN9/kmmuu4f777yc2NrZB/Xn66aeZOXMm8+fPx93dnaqqKtq3b8/q1asJCAhg8+bN3H///bRt25bRo0fXu92YmBiys7P58MMP8fLyYuLEieTl/fzEypkzZ/LMM8806FoudRGjTjDwjnxmTaieA9X5qmIeeOYo3x3z5IP/14ouPU5z633fMiGyK1B30v3hm/58utGXVoHl/O5Px3nilUM8MqoL5aVuHNrfjLnxl3H/00cZOzWHykoL//5bAN/neVBV5VwpWqTGhn+3ZP0af/784iE6hJbw1W5vXn66Ha2Dyhk82vkR+6KTbjx57+Vc1rWEexJyzf2GAYumtqdlQAXzUr7Eq1kVqf9ozVNjOrHw3f20DqoedTrb36WG8eN+owrKS9149IXDtO9cPer7yLxsHhwaSvaXVkK6qJzdZDSJvElc9BEogNtuu42ePXvy9NNPn/V4UlISAwcO5Mknn6Rr167ExMTw4IMP8vzzzwPQqlUr3N3dHUaW6vLYY4/RokULc1u4cKF5LCoqirFjx3L55ZfToUMHPD09eeaZZ7j++uvp1KkTd999NzExMaxevbre17d//37ee+89Xn31VcLDw+nVqxevvfYaxcXFP/ueqVOnUlBQYG7Z2dn1Pp9Ui30yh38uDmTDv/05+Lk369e04s2lbbjroerEtUefIloGVPD69j28e/gz3j38GcEh5cQ+fZTlW/c4tHX6ZPU8kaytLXgutgMhXUrpf3OBefyjFH/+0PMqoq7rzu+vuooVc4Owta4g97BXk16zuI6lz9q588E8Btx6gk7dShj0u3xujz3OqkVBTrd1+pQbT0R1plnzKp5+7QAenj8ey9zUgm0f+DF1yUGu+k0RV1xdzEMzj+DVzOCD1a0A8G9TwffHPR3aPHnCnYpyN1q2qU6wWgVW4O5hmMkTwGVXlACQ943je8X1zJw5k+uvvx5fX18CAwO59dZb2bdvn0OMYRhMmzYNu92Ot7c3AwYMYPfu3Q4xpaWlPPTQQwQEBODj48PIkSM5cuSIQ0x+fj7R0dHYbDZsNhvR0dGcOHHCIebw4cOMGDECHx8fAgICmDhxImVlZQ4xu3btIiIiAm9vb9q1a8f06dMxnJj79YtIoABmz57N8uXL2bNnT61je/fupX///g77+vfvzxdffEFlZaXT53r00UfJzMw0t3vvvdc81rt371rxL7/8Mr1796ZNmza0aNGCpUuXcvjw4Xqfb+/evXh4eDi0feWVV9KyZcuffY/VasXPz89hE+dYm1VhnLEYXFVl9bwngA/W+PPAwK78afCP27c5HvxrSRueiLq87sYthsPt2zVOfOtJyWl3IkadoLzUjU83+p7lzSLnVlrihsXN8XvMzd1wem5v0Uk3Hv9DZzy9DJ5J/hqvZo4NlBZXfwy4nfFp4GYxqPohtHvvIg593ozvjv1YtMjY4IuntYorrj4NwFXXF1FZYeHowR//aDjydfX8raD2KmU3pYtRwtuwYQMTJkwgPT2ddevWUVFRwZAhQygq+nEe6Jw5c0hKSmLx4sVs376d4OBgBg8ezMmTJ82Y+Ph4UlJSWLVqFZs2beLUqVMMHz7c4bM+KiqKzMxMUlNTSU1NJTMzk+joaPN4ZWUlw4YNo6ioiE2bNrFq1SrWrFnDpEmTzJjCwkIGDx6M3W5n+/btLFq0iLlz55KUlFTva77oJbwaN9xwA5GRkTz++OMOc4egOms9c16TM1nimQICAujSpctZj/n4+Di8Xr16NY888gjz5s0jPDwcX19fnn/+ebZu3WrGuLm51erPTyeg1xxz9s5CaZj0dX7cNTGPvG+8qkt4YcXcPv44aauq/6o+me/ByXzHH4GKCgv5eZ4c+ap6QnnwZaVEjDxBxgZfCr73ICC4nNET8igrdmPb+h+To5F//JY9O5pTXOTOdTec5L4nj/K3xLYUFWoCrZyfvoMLWbUwiMB25dUlvCxv3nwlkCF3fWfGFOa7c/wbLzOxyf5hwrl/YDmtAis4fao6eSotdmPKogOcPuXO6R9uirO1rsDdvfpu1Ra2Sp5/+DLufiQXazOD91a2Jjfbi98MrJ57eV3ESS7rWsKchzoQ++RRTp5wZ+l0OzdHfYePb/VfKdfecJIuPU6TlHAZDzzzDYYBix9vz3U3FDqMSkkTaIy76Jx8f2pqqsPrZcuWERgYSEZGBjfccAOGYbBgwQKeeOIJbr/9dgCWL19OUFAQb7zxBuPHj6egoIDXXnuNFStWMGjQIABef/11QkJC+OCDD4iMjGTv3r2kpqaSnp5Onz59AFi6dCnh4eHs27eP0NBQ0tLS2LNnD9nZ2djtdgDmzZtHTEwMM2bMwM/Pj5UrV1JSUkJycjJWq5WwsDD2799PUlISCQkJ9fq8/sUkUACzZs2iZ8+edO3a1WF/9+7d2bRpk8O+zZs307VrV9zdqz+gvLy8zms06lz++9//0q9fP+Li4sx9X331lUNMmzZtyMnJMV9XVlaSlZXFjTfeCEC3bt2oqKhgx44d/OY3vwFg3759tYYcpXG99Jd2jJmSy4Mzj9CydQXfHfPk3RWtWTm//iWQslI3wvoUcVvst7SwVXLiWw92pfvwyKguFHz3Y1kitOdpoifl0syniiNfWlk4pT3r17S6EJcll4i4546wfE5bFk9tz4nvPGgdVM4t0d9y9yPHzJj0NBvzHvlx/aeZf+oIwD0JuURPzuWL/zXn80+r/yj8Y7/uDu0v37qH4JAybK0rmfHGVyTPastjo7tQWW6hQ2gJ05YdoPNV1SU4d3d49u9fs+jx9iSMugIv7ypuvLV6Ic0abm4wffnXvPiX9ky+vQvNmlfR+8ZC7n/6KPLrdeYNTFarFavVes73FRRUT3Fo1ar69+CBAwfIzc1lyJAhDm1FRESwefNmxo8fT0ZGBuXl5Q4xdrudsLAwNm/eTGRkJFu2bMFms5nJE0Dfvn2x2Wxs3ryZ0NBQtmzZQlhYmJk8AURGRlJaWkpGRgY33ngjW7ZsISIiwuFaIiMjmTp1KgcPHqRTp07nvMZfVALVo0cP7r77bhYtWuSwf9KkSVx//fU8++yz3HnnnWzZsoXFixfz0ksvmTEdO3Zk48aN3HXXXVitVgIC6r6rqr66dOnC3//+d95//306derEihUr2L59u8MX96abbiIhIYG1a9fSuXNn5s+f75AchYaGMnToUGJjY/nrX/+Kh4cH8fHxeHt7N0of5eyKi9x5+el2vPx0u3q/Z0wfxw+Z74958mT0Ocp5wPMP117EUKQhmreo4k/Tv+FP07/52Zghd37PkDu//9nj1/Q7xftHM895rq7XFJP4j6/rjAlsX86zfz9QZ0zr4AqeevXgOc8nF1ZjLqQZEhLisP/pp59m2rRpdb7XMAwSEhL47W9/S1hYGAC5udU3LgQFOf4BGxQUxKFDh8wYLy8v/P39a8XUvD83N5fAwMBa5wwMDHSIOfM8/v7+eHl5OcR07Nix1nlqjtUngfrFzIGq8eyzz9Yqh1133XWsXr2aVatWERYWxlNPPcX06dMdSn3Tp0/n4MGDdO7c2VyWoDE88MAD3H777dx555306dOH7777zmE0CmDs2LGMGTOGe++9l4iICDp16mSOPtVYtmwZISEhREREcPvtt3P//fef9ZtARESkQYxG2oDs7GyHG5qmTp16ztM/+OCD/O9//+Mf//hHrWNnm45zrnLZmTFni2+MGGen21zUEajk5ORa+zp06EBJSUmt/XfccQd33HHHz7bVt29fPvvss3Oe8+DBgz977GzzqqxWK8uWLWPZsmUO+3+6bpWnpycvvfSSw4jYmYKDg3nnnXcc9v100puIiMgvjbM3MT300EO8/fbbbNy40WFZopq743Nzc2nbtq25Py8vzxz5CQ4OpqysjPz8fIdRqLy8PPr162fGHDv2Yxm7xvHjxx3a+ek8Zai+c6+8vNwhpmY06qfngdqjZD/nFzcCJSIiIufvYtyFZxgGDz74IG+++SYffvhhrRJYp06dCA4OZt26dea+srIyNmzYYCZHvXr1wtPT0yEmJyeHrKwsMyY8PJyCggK2bdtmxmzdupWCggKHmKysLIe5yWlpaVitVnr16mXGbNy40WFpg7S0NOx2e63S3s9RAiUiIuJKqozG2ZwwYcIEXn/9dd544w18fX3Jzc0lNzfXXO/QYrEQHx9PYmIiKSkpZGVlERMTQ/PmzYmKigLAZrMxbtw4Jk2axPr169m5cyf33HMPPXr0MO/K69atmzmnOD09nfT0dGJjYxk+fDihoaEADBkyhO7duxMdHc3OnTtZv349kydPJjY21hxNi4qKwmq1EhMTQ1ZWFikpKSQmJtb7Djz4hU0iFxERkQa6CCuRL1myBKh+tNlPLVu2zJyvPGXKFIqLi4mLiyM/P58+ffqQlpaGr++PS8LMnz8fDw8PRo8eTXFxMQMHDiQ5Odm84x5g5cqVTJw40bxbb+TIkSxevNg87u7uztq1a4mLi6N///54e3sTFRXF3LlzzRibzca6deuYMGECvXv3xt/fn4SEBBISEup9zRajIQsqSZMpLCzEZrMxgFF4WLSqr7im+twxJvJrVXiyCv+uX1NQUHBBFkeu+ZzoN+gZPDzP/XD0ulSUl7D5g6cvWF9dgUagREREXIiFRljGoFF64tqUQImIiLiSi7AS+aVIk8hFREREnKQRKBERERfSmCuRy89TAiUiIuJKLsJdeJcilfBEREREnKQRKBERERdiMQwsDZwE3tD3XwqUQImIiLiSqh+2hrYhdVIJT0RERMRJGoESERFxISrhNQ0lUCIiIq5Ed+E1CSVQIiIirkQrkTcJzYESERERcZJGoERERFyIViJvGkqgREREXIlKeE1CJTwRERERJ2kESkRExIVYqqq3hrYhdVMCJSIi4kpUwmsSKuGJiIiIOEkjUCIiIq5EC2k2CSVQIiIiLkSPcmkaKuGJiIiIOEkjUCIiIq5Ek8ibhBIoERERV2IADV2GQPnTOSmBEhERcSGaA9U0NAdKRERExEkagRIREXElBo0wB6pReuLSlECJiIi4Ek0ibxIq4YmIiIg4SSNQIiIirqQKsDRCG1InJVAiIiIuRHfhNQ2V8EREREScpBEoERERV6JJ5E1CCZSIiIgrUQLVJFTCExEREXGSEigRERFXUjMC1dDNCRs3bmTEiBHY7XYsFgtvvfXWGV0ymDZtGna7HW9vbwYMGMDu3bsdYkpLS3nooYcICAjAx8eHkSNHcuTIEYeY/Px8oqOjsdls2Gw2oqOjOXHihEPM4cOHGTFiBD4+PgQEBDBx4kTKysocYnbt2kVERATe3t60a9eO6dOnYzh5zUqgREREXElVI21OKCoq4pprrmHx4sVnPT5nzhySkpJYvHgx27dvJzg4mMGDB3Py5EkzJj4+npSUFFatWsWmTZs4deoUw4cPp7Ky0oyJiooiMzOT1NRUUlNTyczMJDo62jxeWVnJsGHDKCoqYtOmTaxatYo1a9YwadIkM6awsJDBgwdjt9vZvn07ixYtYu7cuSQlJTl1zZoDJSIi4kIuxjIGN998MzfffPNZjxmGwYIFC3jiiSe4/fbbAVi+fDlBQUG88cYbjB8/noKCAl577TVWrFjBoEGDAHj99dcJCQnhgw8+IDIykr1795Kamkp6ejp9+vQBYOnSpYSHh7Nv3z5CQ0NJS0tjz549ZGdnY7fbAZg3bx4xMTHMmDEDPz8/Vq5cSUlJCcnJyVitVsLCwti/fz9JSUkkJCRgsdRvES2NQImIiMhZFRYWOmylpaVOt3HgwAFyc3MZMmSIuc9qtRIREcHmzZsByMjIoLy83CHGbrcTFhZmxmzZsgWbzWYmTwB9+/bFZrM5xISFhZnJE0BkZCSlpaVkZGSYMREREVitVoeYo0ePcvDgwXpflxIoERERV9KIc6BCQkLM+UY2m42ZM2c63Z3c3FwAgoKCHPYHBQWZx3Jzc/Hy8sLf37/OmMDAwFrtBwYGOsSceR5/f3+8vLzqjKl5XRNTHyrhiYiIuJIqAywNXIagqvr92dnZ+Pn5mbt/OmrjrDNLY4ZhnLNcdmbM2eIbI6ZmAnl9y3egESgRERH5GX5+fg7b+SRQwcHBQO3Rnby8PHPkJzg4mLKyMvLz8+uMOXbsWK32jx8/7hBz5nny8/MpLy+vMyYvLw+oPUpWFyVQIiIiruQiLGNQl06dOhEcHMy6devMfWVlZWzYsIF+/foB0KtXLzw9PR1icnJyyMrKMmPCw8MpKChg27ZtZszWrVspKChwiMnKyiInJ8eMSUtLw2q10qtXLzNm48aNDksbpKWlYbfb6dixY72vSwmUiIiIS2mM5Mm5BOrUqVNkZmaSmZkJVE8cz8zM5PDhw1gsFuLj40lMTCQlJYWsrCxiYmJo3rw5UVFRANhsNsaNG8ekSZNYv349O3fu5J577qFHjx7mXXndunVj6NChxMbGkp6eTnp6OrGxsQwfPpzQ0FAAhgwZQvfu3YmOjmbnzp2sX7+eyZMnExsba5Yio6KisFqtxMTEkJWVRUpKComJiU7dgQeaAyUiIiINtGPHDm688UbzdUJCAgBjxowhOTmZKVOmUFxcTFxcHPn5+fTp04e0tDR8fX3N98yfPx8PDw9Gjx5NcXExAwcOJDk5GXd3dzNm5cqVTJw40bxbb+TIkQ5rT7m7u7N27Vri4uLo378/3t7eREVFMXfuXDPGZrOxbt06JkyYQO/evfH39ychIcHsc31ZDGeX3pSLorCwEJvNxgBG4WHxvNjdEbkg3j+aebG7IHLBFJ6swr/r1xQUFDhMzG609n/4nBjU6SE83M5/sjdARVUpHxxYdMH66go0AiUiIuJKqpwvwZ29DamL5kCJiIiIOEkjUCIiIq7EqKreGtqG1EkJlIiIiCtpjGUIND36nJRAiYiIuBLNgWoSmgMlIiIi4iSNQImIiLgSlfCahBIoERERV2LQCAlUo/TEpamEJyIiIuIkjUCJiIi4EpXwmoQSKBEREVdSVQU0cB2nKq0DdS4q4YmIiIg4SSNQIiIirkQlvCahBEpERMSVKIFqEirhiYiIiDhJI1AiIiKuRI9yaRJKoERERFyIYVRhGA27i66h778UKIESERFxJYbR8BEkzYE6J82BEhEREXGSRqBERERcidEIc6A0AnVOSqBERERcSVUVWBo4h0lzoM5JJTwRERERJ2kESkRExJWohNcklECJiIi4EKOqCqOBJTwtY3BuKuGJiIiIOEkjUCIiIq5EJbwmoQRKRETElVQZYFECdaGphCciIiLiJI1AiYiIuBLDABq6DpRGoM5FCZSIiIgLMaoMjAaW8AwlUOekBEpERMSVGFU0fARKyxici+ZAiYiIiDhJI1AiIiIuRCW8pqEESkRExJWohNcklED9StT8NVBBeYPXRxP5pSo8qV/a4roKT1V/f1/o0Z3G+JyooLxxOuPClED9Spw8eRKATbx7kXsicuH4d73YPRC58E6ePInNZmv0dr28vAgODmZTbuN8TgQHB+Pl5dUobbkii6FC569CVVUVR48exdfXF4vFcrG74/IKCwsJCQkhOzsbPz+/i90dkUan7/GmZxgGJ0+exG634+Z2Ye7hKikpoaysrFHa8vLyolmzZo3SlivSCNSvhJubG+3bt7/Y3bjk+Pn56cNFXJq+x5vWhRh5+qlmzZop6WkiWsZARERExElKoEREREScpARK5CysVitPP/00Vqv1YndF5ILQ97hIw2gSuYiIiIiTNAIlIiIi4iQlUCIiIiJOUgIlIiIi4iQlUCIXSExMDLfeeuvF7obIL1LHjh1ZsGDBxe6GyHlTAiUuJyYmBovFUmv78ssvL3bXREw136ezZs1y2P/WW285/bSB+iYjHTt2rPVzoQV6Rc6PEihxSUOHDiUnJ8dh69Spk0NMYz3uQOR8NWvWjNmzZ5Ofn99k55w+fbrDz8XOnTvPGlderofJitRFCZS4JKvVSnBwsMM2cOBAHnzwQRISEggICGDw4MEAJCUl0aNHD3x8fAgJCSEuLo5Tp06ZbU2bNo2ePXs6tL9gwQI6duxovq6srCQhIYGWLVvSunVrpkyZcsGfuC6/foMGDSI4OJiZM2fWGbdmzRquuuoqrFYrHTt2ZN68eeaxAQMGcOjQIR555BFzVKkuvr6+Dj8Xbdq0AcBisfDyyy8zatQofHx8eO6556isrGTcuHF06tQJb29vQkNDeeGFFxzaGzBgAPHx8Q77br31VmJiYszXeXl5jBgxAm9vbzp16sTKlSvr8dUR+WVTAiWXlOXLl+Ph4cEnn3zCK6+8AlQ/Z3DhwoVkZWWxfPlyPvzwQ6ZMmeJUu/PmzeNvf/sbr732Gps2beL7778nJSXlQlyCuBB3d3cSExNZtGgRR44cOWtMRkYGo0eP5q677mLXrl1MmzaNJ598kuTkZADefPNN2rdv7zCydL6efvppRo0axa5duxg7dixVVVW0b9+e1atXs2fPHp566ikef/xxVq9e7VS7MTExHDx4kA8//JB//etfvPTSS+Tl5Z13P0V+EQwRFzNmzBjD3d3d8PHxMbff/e53RkREhNGzZ89zvn/16tVG69atzddPP/20cc011zjEzJ8/3+jQoYP5um3btsasWbPM1+Xl5Ub79u2NUaNGNfRyxEWNGTPG/P7o27evMXbsWMMwDCMlJcX46a/mqKgoY/DgwQ7vffTRR43u3bubrzt06GDMnz//nOfs0KGD4eXl5fCz8cILLxiGYRiAER8ff8424uLijDvuuMN8HRERYTz88MMOMaNGjTLGjBljGIZh7Nu3zwCM9PR08/jevXsNoF59Fvml8ri46ZvIhXHjjTeyZMkS87WPjw9/+MMf6N27d63Yjz76iMTERPbs2UNhYSEVFRWUlJRQVFSEj4/POc9VUFBATk4O4eHh5j4PDw969+6tMp7Uy+zZs7npppuYNGlSrWN79+5l1KhRDvv69+/PggULqKysxN3d3alzPfroow7ltYCAAPPfZ/v5ePnll3n11Vc5dOgQxcXFlJWV1Spp12Xv3r3mz0ONK6+8kpYtWzrVb5FfGpXwxCX5+PjQpUsXc2vbtq25/6cOHTrELbfcQlhYGGvWrCEjI4MXX3wR+HESrZubW61ESBNspTHdcMMNREZG8vjjj9c6ZhhGrXlNDUnMAwICHH42fprInPnzsXr1ah555BHGjh1LWloamZmZ/PGPf3S4AeNcPx81x5y9s1Dkl04JlFzSduzYQUVFBfPmzaNv37507dqVo0ePOsS0adOG3Nxchw+JzMxM8982m422bduSnp5u7quoqCAjI+OC919cx6xZs/jPf/7D5s2bHfZ3796dTZs2OezbvHkzXbt2NUefvLy8qKysbPQ+/fe//6Vfv37ExcVx7bXX0qVLF7766iuHmDZt2jjMu6qsrCQrK8t83a1bNyoqKtixY4e5b9++fZw4caLR+yvSlJRAySWtc+fOVFRUsGjRIr7++mtWrFjByy+/7BAzYMAAjh8/zpw5c/jqq6948cUXee+99xxiHn74YWbNmkVKSgqff/45cXFx+oAQp/To0YO7776bRYsWOeyfNGkS69ev59lnn2X//v0sX76cxYsXM3nyZDOmY8eObNy4kW+++YZvv/220frUpUsXduzYwfvvv8/+/ft58skn2b59u0PMTTfdxNq1a1m7du1Zv/dDQ0MZOnQosbGxbN26lYyMDO677z68vb0brZ8iF4MSKLmk9ezZk6SkJGbPnk1YWBgrV66sdUt5t27deOmll3jxxRe55ppr2LZtm8OHF1R/yN17773ExMQQHh6Or68vt912W1NeiriAZ599tlY57LrrrmP16tWsWrWKsLAwnnrqKaZPn+4wj2n69OkcPHiQzp07m8sSNIYHHniA22+/nTvvvJM+ffrw3XffERcX5xAzduxYxowZw7333ktERASdOnXixhtvdIhZtmwZISEhREREcPvtt3P//fcTGBjYaP0UuRgshma5ioiIiDhFI1AiIiIiTlICJSIiIuIkJVAiIiIiTlICJSIiIuIkJVAiIiIiTlICJSIiIuIkJVAiIiIiTlICJSIiIuIkJVAiUm/Tpk2jZ8+e5uuYmBhuvfXWJu/HwYMHsVgsDs8kPFPHjh1ZsGBBvdtMTk52eLDu+bJYLLz11lsNbkdEftmUQIn8ysXExGCxWLBYLHh6enL55ZczefJkioqKLvi5X3jhBZKTk+sVW5+kR0Tk18LjYndARBpu6NChLFu2jPLycv773/9y3333UVRUxJIlS2rFlpeX4+np2SjntdlsjdKOiMivjUagRFyA1WolODiYkJAQoqKiuPvuu80yUk3Z7W9/+xuXX345VqsVwzAoKCgwH+rq5+fHTTfdxGeffebQ7qxZswgKCsLX15dx48ZRUlLicPzMEl5VVRWzZ8+mS5cuWK1WLrvsMmbMmAFAp06dALj22muxWCwMGDDAfN+yZcvo1q0bzZo148orr+Sll15yOM+2bdu49tpradasGb1792bnzp1Of42SkpLo0aMHPj4+hISEEBcXx6lTp2rFvfXWW3Tt2pVmzZoxePBgsrOzHY7/5z//oVevXjRr1ozLL7+cZ555hoqKCqf7IyK/bkqgRFyQt7c35eXl5usvv/yS1atXs2bNGrOENmzYMHJzc3n33XfJyMjguuuuY+DAgXz//fcArF69mqeffpoZM2awY8cO2rZtWyuxOdPUqVOZPXs2Tz75JHv27OGNN94gKCgIqE6CAD744ANycnJ48803AVi6dClPPPEEM2bMYO/evSQmJvLkk0+yfPlyAIqKihg+fDihoaFkZGQwbdo0Jk+e7PTXxM3NjYULF5KVlcXy5cv58MMPmTJlikPM6dOnmTFjBsuXL+eTTz6hsLCQu+66yzz+/vvvc8899zBx4kT27NnDK6+8QnJyspkkisglxBCRX7UxY8YYo0aNMl9v3brVaN26tTF69GjDMAzj6aefNjw9PY28vDwzZv369Yafn59RUlLi0Fbnzp2NV155xTAMwwgPDzceeOABh+N9+vQxrrnmmrOeu7Cw0LBarcbSpUvP2s8DBw4YgLFz506H/SEhIcYbb7zhsO/ZZ581wsPDDcMwjFdeecVo1aqVUVRUZB5fsmTJWdv6qQ4dOhjz58//2eOrV682Wrdubb5etmyZARjp6enmvr179xqAsXXrVsMwDOP//u//jMTERId2VqxYYbRt29Z8DRgpKSk/e14RcQ2aAyXiAt555x1atGhBRUUF5eXljBo1ikWLFpnHO3ToQJs2bczXGRkZnDp1itatWzu0U1xczFdffQXA3r17eeCBBxyOh4eH89FHH521D3v37qW0tJSBAwfWu9/Hjx8nOzubcePGERsba+6vqKgw51ft3buXa665hubNmzv0w1kfffQRiYmJ7Nmzh8LCQioqKigpKaGoqAgfHx8APDw86N27t/meK6+8kpYtW7J3715+85vfkJGRwfbt2x1GnCorKykpKeH06dMOfRQR16YESsQF3HjjjSxZsgRPT0/sdnutSeI1CUKNqqoq2rZty8cff1yrrfO9ld/b29vp91RVVQHVZbw+ffo4HHN3dwfAMIzz6s9PHTp0iFtuuYUHHniAZ599llatWrFp0ybGjRvnUOqE6mUIzlSzr6qqimeeeYbbb7+9VkyzZs0a3E8R+fVQAiXiAnx8fOjSpUu946+77jpyc3Px8PCgY8eOZ43p1q0b6enp3Hvvvea+9PT0n23ziiuuwNvbm/Xr13PffffVOu7l5QVUj9jUCAoKol27dnz99dfcfffdZ223e/furFixguLiYjNJq6sfZ7Njxw4qKiqYN28ebm7VUz9Xr15dK66iooIdO3bwm9/8BoB9+/Zx4sQJrrzySqD667Zv3z6nvtYi4pqUQIlcggYNGkR4eDi33nors2fPJjQ0lKNHj/Luu+9y66230rt3bx5++GHGjBlD7969+e1vf8vKlSvZvXs3l19++VnbbNasGY899hhTpkzBy8uL/v37c/z4cXbv3s24ceMIDAzE29ub1NRU2rdvT7NmzbDZbEybNo2JEyfi5+fHzTffTGlpKTt27CA/P5+EhASioqJ44oknGDduHH/5y184ePAgc+fOdep6O3fuTEVFBYsWLWLEiBF88sknvPzyy7XiPD09eeihh1i4cCGenp48+OCD9O3b10yonnrqKYYPH05ISAi///3vcXNz43//+x+7du3iueeec/5/hIj8aukuPJFLkMVi4d133+WGG25g7NixdO3albvuuouDBw+ad83deeedPPXUUzz22GP06tWLQ4cO8ac//anOdp988kkmTZrEU089Rbdu3bjzzjvJy8sDqucXLVy4kFdeeQW73c6oUaMAuO+++3j11VdJTk6mR48eREREkJycbC570KJFC/7zn/+wZ88err32Wp544glmz57t1PX27NmTpKQkZs+eTVhYGCtXrmTmzJm14po3b85jjz1GVFQU4eHheHt7s2rVKvN4ZGQk77zzDuvWreP666+nb9++JCUl0aFDB6f6IyK/fhajMSYYiIiIiFxCNAIlIiIi4iQlUCIiIiJOUgIlIiIi4iQlUCIiIiJOUgIlIiIi4iQlUCIiIiJOUgIlIiIi4iQlUCIiIiJOUgIlIiIi4iQlUCIiIiJOUgIlIiIi4qT/DxNs0pid3aDtAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "e7a3c291369346e8a2b8cfbb9adc062f",
    "deepnote_app_block_visible": false,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Naive Bayes - by hand\n",
    "\n",
    "Our goal in this section is to perform Naive Bayes \"by hand\" (or at least without using a scikit-learn model).  Recall that Naive Bayes is based on the following formula, taken from Section 4.4 of ISLP:\n",
    "\n",
    "![Formula 4.30](naiveBayes.png)\n",
    "\n",
    "In our case, $k$ will represent either \"Fraud\" or \"Not Fraud\".  The function $f_{ki}(x_i)$ represents the probability (or probability density) of the i-th predictor being $x_i$ in class $k$.  To estimate these functions $f_{ki}$, we will use the first and third bullet points beneath Equation (4.30) in ISLP, according to whether the variable is a float type or a Boolean type.  The term $\\pi_k$ represents *prior* probability of class $k$ (*prior* meaning without dependence on the predictors $x_i$).\n",
    "\n",
    "Strategy:\n",
    "* We first compute the values $\\pi_k$.\n",
    "* We then (prepare to) compute the functions $f_{ki}$ when $i$ represents a float column.\n",
    "* We then (prepare to) compute the functions $f_{ki}$ when $i$ represents a Boolean column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "25af01516ac24ba4a1ea9bb499668fa1",
    "deepnote_app_block_visible": false,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "* Define a dictionary `prior_dct` representing the two prior values $\\pi_{Fraud}$ and $\\pi_{Not Fraud}$, as in the following template.\n",
    "```\n",
    "prior_dct = {\n",
    "    \"Fraud\": ???,\n",
    "    \"Not Fraud\": ???\n",
    "}\n",
    "```\n",
    "Reality check: the two values should sum to (approximately) 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "cell_id": "b50aead3284a403ab50a7fd24333edfc",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 49,
    "execution_start": 1713199486851,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "p = (y_train == \"Fraud\").mean()\n",
    "\n",
    "prior_dct = {\n",
    "    \"Fraud\": p,\n",
    "    \"Not Fraud\": 1-p\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "cell_id": "b6df3dbad77f4b83993ae8a65fd5adb3",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 106,
    "execution_start": 1713199487665,
    "source_hash": null
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Fraud': 0.08648, 'Not Fraud': 0.91352}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prior_dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.91352\n"
     ]
    }
   ],
   "source": [
    "p1 = (y_train != \"Fraud\").mean()\n",
    "print(p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Fraud': 0.08648, 'Not Fraud': 0.91352}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = (y_train == \"Fraud\").mean()\n",
    "p1 = (y_train == \"Not Fraud\").mean()\n",
    "#p1 = (y_train != \"Fraud\").mean()\n",
    "\n",
    "prior_dct_v2 = {\n",
    "    \"Fraud\": p,\n",
    "    \"Not Fraud\": p1\n",
    "}\n",
    "prior_dct_v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "b4af2670953e414187494201886a58b3",
    "deepnote_app_block_visible": false,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "* It's temporarily convenient here to have `X_train` and `y_train` together in the same DataFrame.  Concatenate these together along the columns axis and name the result `df_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "cell_id": "0ca48987f6aa40fa9539b3418552a783",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 105,
    "execution_start": 1713199489467,
    "source_hash": null
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance_from_home</th>\n",
       "      <th>distance_from_last_transaction</th>\n",
       "      <th>ratio_to_median_purchase_price</th>\n",
       "      <th>repeat_retailer</th>\n",
       "      <th>used_chip</th>\n",
       "      <th>used_pin_number</th>\n",
       "      <th>online_order</th>\n",
       "      <th>fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>396645</th>\n",
       "      <td>31.349377</td>\n",
       "      <td>0.205349</td>\n",
       "      <td>0.938398</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Not Fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23311</th>\n",
       "      <td>1.296644</td>\n",
       "      <td>1.320207</td>\n",
       "      <td>4.292744</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898602</th>\n",
       "      <td>1.920492</td>\n",
       "      <td>3.845230</td>\n",
       "      <td>0.536337</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Not Fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717543</th>\n",
       "      <td>62.282390</td>\n",
       "      <td>2.345352</td>\n",
       "      <td>0.691888</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Not Fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777825</th>\n",
       "      <td>0.954158</td>\n",
       "      <td>7.821139</td>\n",
       "      <td>0.568286</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Not Fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572344</th>\n",
       "      <td>3.169406</td>\n",
       "      <td>3.070521</td>\n",
       "      <td>0.684865</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Not Fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452227</th>\n",
       "      <td>4.656197</td>\n",
       "      <td>2.625558</td>\n",
       "      <td>1.997541</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Not Fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601337</th>\n",
       "      <td>218.787696</td>\n",
       "      <td>0.070694</td>\n",
       "      <td>0.624996</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Not Fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722584</th>\n",
       "      <td>3.990084</td>\n",
       "      <td>2.192464</td>\n",
       "      <td>0.833127</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Not Fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71530</th>\n",
       "      <td>15.153602</td>\n",
       "      <td>0.887351</td>\n",
       "      <td>1.034983</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Not Fraud</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        distance_from_home  distance_from_last_transaction  \\\n",
       "396645           31.349377                        0.205349   \n",
       "23311             1.296644                        1.320207   \n",
       "898602            1.920492                        3.845230   \n",
       "717543           62.282390                        2.345352   \n",
       "777825            0.954158                        7.821139   \n",
       "...                    ...                             ...   \n",
       "572344            3.169406                        3.070521   \n",
       "452227            4.656197                        2.625558   \n",
       "601337          218.787696                        0.070694   \n",
       "722584            3.990084                        2.192464   \n",
       "71530            15.153602                        0.887351   \n",
       "\n",
       "        ratio_to_median_purchase_price  repeat_retailer  used_chip  \\\n",
       "396645                        0.938398             True       True   \n",
       "23311                         4.292744            False      False   \n",
       "898602                        0.536337             True       True   \n",
       "717543                        0.691888             True      False   \n",
       "777825                        0.568286            False      False   \n",
       "...                                ...              ...        ...   \n",
       "572344                        0.684865             True      False   \n",
       "452227                        1.997541             True      False   \n",
       "601337                        0.624996             True       True   \n",
       "722584                        0.833127             True       True   \n",
       "71530                         1.034983             True      False   \n",
       "\n",
       "        used_pin_number  online_order      fraud  \n",
       "396645            False          True  Not Fraud  \n",
       "23311             False          True      Fraud  \n",
       "898602            False         False  Not Fraud  \n",
       "717543            False         False  Not Fraud  \n",
       "777825            False          True  Not Fraud  \n",
       "...                 ...           ...        ...  \n",
       "572344            False          True  Not Fraud  \n",
       "452227            False         False  Not Fraud  \n",
       "601337            False          True  Not Fraud  \n",
       "722584            False         False  Not Fraud  \n",
       "71530             False         False  Not Fraud  \n",
       "\n",
       "[100000 rows x 8 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.concat([X_train, y_train], axis=1)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "d637c02505b64bbf8ea9e795181ca86d",
    "deepnote_app_block_visible": false,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "* Write a function `Gaussian_helper` which takes a DataFrame input `df` and two string inputs, a class `k` (which will be \"Not Fraud\" or \"Fraud\" in our case) and a column name `col` of one of the float columns.  The output should be a dictionary with keys `\"mean\"` and `\"std\"`, representing the mean and the standard deviation for the given column within the given class, as in the first bullet point after (4.30).  \n",
    "\n",
    "Comment: To find the mean and standard deviation, you can use the formulas in (4.20) (take the square root of the variance to get the standard deviation), but I think it's easier to just let pandas compute these for you, using the `mean` and `std` methods of a pandas Series.  It's possible pandas will use $n$ instead of the $n-K$ in Equation (4.20), but that shouldn't be significant here because $n$ is so big and $K=2$. \n",
    "\n",
    "Here is a possible template:\n",
    "```\n",
    "def Gaussian_helper(df, k, col):\n",
    "    output_dct = {}\n",
    "    ... # one or more lines here\n",
    "    output_dct[\"mean\"] = ...\n",
    "    output_dct[\"std\"] = ...\n",
    "    return output_dct\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "cell_id": "74356a042dda4c6993d403b70e2698b6",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 98,
    "execution_start": 1713199492528,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "def Gaussian_helper(df, k, col):\n",
    "    output_dct = {}\n",
    "    ser = df.loc[df[\"fraud\"] == k, col]\n",
    "    output_dct[\"mean\"] = ser.mean()\n",
    "    output_dct[\"std\"] = ser.std()\n",
    "    return output_dct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "a0040b0c875e4cb08cce21b7bb47ab43",
    "deepnote_app_block_visible": false,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "* Similarly, write a function `Boolean_helper` which takes a DataFrame input `df` and two string inputs, a class `k` (which will be \"Not Fraud\" or \"Fraud\" in our case) and a column name `col` of one of the Boolean columns.  The output should be a dictionary with keys `True` and `False`, representing the proportion of these values within the given class.  For an example, see the third bullet point after (4.30) in the textbook.\n",
    "\n",
    "Comment: Make sure your keys are `bool` values, not strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "cell_id": "adf0d80865624b5b9056f7dd933db397",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 337,
    "execution_start": 1713199494908,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "def Boolean_helper(df, k, col):\n",
    "    output_dct = {}\n",
    "    ser = df.loc[df[\"fraud\"] == k, col]\n",
    "    p = ser.mean()\n",
    "    output_dct[True] = p\n",
    "    output_dct[False] = 1-p\n",
    "    return output_dct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "819e296f04f7426db040a809f804de54",
    "deepnote_app_block_visible": false,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "* Check your helper functions by comparing a few of their outputs to the following.  (I feel like there is probably a nice way to use the following DataFrame directly and never define the helper functions, but I did not succeed in doing that.)\n",
    "\n",
    "```\n",
    "df_train.groupby(\"fraud\").mean()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "cell_id": "a010769162114ae9be3ed2adba4200d6",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 489,
    "execution_start": 1713199268189,
    "source_hash": null
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance_from_home</th>\n",
       "      <th>distance_from_last_transaction</th>\n",
       "      <th>ratio_to_median_purchase_price</th>\n",
       "      <th>repeat_retailer</th>\n",
       "      <th>used_chip</th>\n",
       "      <th>used_pin_number</th>\n",
       "      <th>online_order</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fraud</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Fraud</th>\n",
       "      <td>66.947603</td>\n",
       "      <td>13.072574</td>\n",
       "      <td>5.989062</td>\n",
       "      <td>0.880666</td>\n",
       "      <td>0.253353</td>\n",
       "      <td>0.002891</td>\n",
       "      <td>0.947849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Not Fraud</th>\n",
       "      <td>22.762880</td>\n",
       "      <td>4.293053</td>\n",
       "      <td>1.414935</td>\n",
       "      <td>0.882509</td>\n",
       "      <td>0.362696</td>\n",
       "      <td>0.108547</td>\n",
       "      <td>0.621639</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           distance_from_home  distance_from_last_transaction  \\\n",
       "fraud                                                           \n",
       "Fraud               66.947603                       13.072574   \n",
       "Not Fraud           22.762880                        4.293053   \n",
       "\n",
       "           ratio_to_median_purchase_price  repeat_retailer  used_chip  \\\n",
       "fraud                                                                   \n",
       "Fraud                            5.989062         0.880666   0.253353   \n",
       "Not Fraud                        1.414935         0.882509   0.362696   \n",
       "\n",
       "           used_pin_number  online_order  \n",
       "fraud                                     \n",
       "Fraud             0.002891      0.947849  \n",
       "Not Fraud         0.108547      0.621639  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.groupby(\"fraud\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "cell_id": "c814761ad7194d1cb5cfaec5a6939098",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 142,
    "execution_start": 1713199270804,
    "source_hash": null
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean': 4.293053194701276, 'std': 18.698566502771733}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Gaussian_helper(df_train, \"Not Fraud\", 'distance_from_last_transaction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean': 13.07257438605343, 'std': 48.91467336597028}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Gaussian_helper(df_train, \"Fraud\", 'distance_from_last_transaction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "cell_id": "17973b49a90744ea90b5c0ef509fed0b",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 150,
    "execution_start": 1713199271383,
    "source_hash": null
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{True: 0.36269594535423416, False: 0.6373040546457658}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Boolean_helper(df_train, \"Not Fraud\", 'used_chip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "bbe7d54c6c3144dca3e172c9c07ee959",
    "deepnote_app_block_visible": false,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "Here is an example of applying the Gaussian probability density function with mean 10 and standard deviation 4 to every entry in a column, without explicitly using any loops.\n",
    "\n",
    "```\n",
    "from scipy.stats import norm\n",
    "\n",
    "norm.pdf(X_train[\"distance_from_last_transaction\"], loc=10, scale=4)\n",
    "```\n",
    "\n",
    "You should view the outputs as representing the probability (densities) of the given Gaussian distribution producing the input values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "cell_id": "b11afa51b9024b7c8a82f4b35159e73b",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 351,
    "execution_start": 1713199498884,
    "source_hash": null
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00497561, 0.00947053, 0.03053078, ..., 0.00457932, 0.01484402,\n",
       "       0.00744476])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "norm.pdf(X_train[\"distance_from_last_transaction\"], loc=10, scale=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "991cd649768c4f58ba76758130e76ea5",
    "deepnote_app_block_visible": false,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "Here is an example of using a dictionary to replace every value in a column.  Think of the values in this dictionary as our estimated probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "cell_id": "a22378b9e52c4d3aab9d902b6ce568a9",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 235,
    "execution_start": 1713199502843,
    "source_hash": null
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "396645    0.71\n",
       "23311     0.29\n",
       "898602    0.71\n",
       "717543    0.29\n",
       "777825    0.29\n",
       "          ... \n",
       "572344    0.29\n",
       "452227    0.29\n",
       "601337    0.71\n",
       "722584    0.71\n",
       "71530     0.29\n",
       "Name: used_chip, Length: 100000, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_dct = {True: 0.71, False: 0.29}\n",
    "\n",
    "X_train[\"used_chip\"].map(temp_dct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "68e1fdeb195c4ec29fa156c6c5796b53",
    "deepnote_app_block_visible": false,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "Momentarily fix the class $k$ to be \"Fraud\".  We are going to compute the numerator of Equation (4.30) for every row of `X_train`.  (Here we switch back to using `X_train` rather than `df_train`.)\n",
    "\n",
    "Do all of the following in a single code cell.  (The reason for not separating the cells is so that the entire cell can be run again easily.)\n",
    "\n",
    "* Assign `k = \"Fraud\"`.\n",
    "* Copy the `X_train` DataFrame into a new DataFrame called `X_temp`.  Use the `copy` method.\n",
    "* For each column of `X_temp`, use `Gaussian_helper` or `Boolean_helper`, as appropriate, to replace each value $x_i$ with $f(x_i)$, where $f$ is as in (4.30).  You can use a for loop to loop over the columns, but within a fixed column, you should not need to use a for loop (in other words, you should not need to loop over the rows, only over the columns).  The following imports might be helpful for determining the data types (make the imports outside of any for loop).\n",
    "```\n",
    "from pandas.api.types import is_bool_dtype, is_float_dtype\n",
    "```\n",
    "\n",
    "Comment: Your code should be changing the `X_temp` entries but not the `X_train` entries.  When you are finished, `X_temp` will be a DataFrame containing probabilities, all corresponding to the \"Fraud\" class.\n",
    "\n",
    "* For each row, multiply all entries in that row.  (Hint.  DataFrames have a `prod` method.)  Also multiply by the prior probability of \"Fraud\".  (Use `k`, do not type `\"Fraud\"`.)  The end result should be a pandas Series corresponding to the numerator of (4.30), for each row of `X_train`.  Don't be surprised if the numbers are very small, like around $10^{-10}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "cell_id": "400563130455491eac018fec2faf24b6",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 178,
    "execution_start": 1713199509427,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "from pandas.api.types import is_bool_dtype, is_float_dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "cell_id": "845ce4765f484462af41e9f6325a3260",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 129,
    "execution_start": 1713199282386,
    "source_hash": null
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "396645    2.033245e-08\n",
       "23311     1.084820e-08\n",
       "898602    9.706474e-10\n",
       "717543    3.315339e-09\n",
       "777825    7.144284e-09\n",
       "              ...     \n",
       "572344    5.347774e-08\n",
       "452227    3.615439e-09\n",
       "601337    1.001793e-08\n",
       "722584    1.023674e-09\n",
       "71530     3.222440e-09\n",
       "Length: 100000, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = \"Fraud\"\n",
    "X_temp = X_train.copy()\n",
    "\n",
    "for c in X_temp.columns:\n",
    "    if is_float_dtype(X_train[c]):\n",
    "        dct = Gaussian_helper(df_train, k, c)\n",
    "        loc = dct[\"mean\"]\n",
    "        scale = dct[\"std\"]\n",
    "        X_temp[c] = norm.pdf(X_temp[c], loc=loc, scale=scale)\n",
    "    elif is_bool_dtype(X_train[c]):\n",
    "        dct = Boolean_helper(df_train, k, c)\n",
    "        X_temp[c] = X_temp[c].map(dct)\n",
    "\n",
    "X_temp.prod(axis=1)*prior_dct[k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "377f477454d54e5e8bccc03c916b3fbf",
    "deepnote_app_block_visible": false,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "* Once the code is working, wrap the whole thing into another for loop, corresponding to `k = \"Fraud\"` and `k = \"Not Fraud\"`, putting the two resulting pandas Series into a length 2 dictionary with keys `\"Fraud\"` and `\"Not Fraud\"`.  Call this dictionary `num_dct`, because it represents the numerators of (4.30)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "cell_id": "3b0fa67a8b1b4d25af3ebc19786c34e3",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 387,
    "execution_start": 1713199512445,
    "source_hash": null
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Fraud': 396645    2.033245e-08\n",
       " 23311     1.084820e-08\n",
       " 898602    9.706474e-10\n",
       " 717543    3.315339e-09\n",
       " 777825    7.144284e-09\n",
       "               ...     \n",
       " 572344    5.347774e-08\n",
       " 452227    3.615439e-09\n",
       " 601337    1.001793e-08\n",
       " 722584    1.023674e-09\n",
       " 71530     3.222440e-09\n",
       " Length: 100000, dtype: float64,\n",
       " 'Not Fraud': 396645    5.416763e-06\n",
       " 23311     3.816276e-07\n",
       " 898602    2.910761e-06\n",
       " 717543    4.215607e-06\n",
       " 777825    1.098875e-06\n",
       "               ...     \n",
       " 572344    8.761946e-06\n",
       " 452227    5.531373e-06\n",
       " 601337    2.572111e-09\n",
       " 722584    3.125787e-06\n",
       " 71530     5.922533e-06\n",
       " Length: 100000, dtype: float64}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_dct = {}\n",
    "\n",
    "for k in [\"Fraud\", \"Not Fraud\"]:\n",
    "    X_temp = X_train.copy()\n",
    "\n",
    "    for c in X_temp.columns:\n",
    "        if is_float_dtype(X_train[c]):\n",
    "            dct = Gaussian_helper(df_train, k, c)\n",
    "            loc = dct[\"mean\"]\n",
    "            scale = dct[\"std\"]\n",
    "            X_temp[c] = norm.pdf(X_temp[c], loc=loc, scale=scale)\n",
    "        elif is_bool_dtype(X_train[c]):\n",
    "            dct = Boolean_helper(df_train, k, c)\n",
    "            X_temp[c] = X_temp[c].map(dct)\n",
    "\n",
    "    num_dct[k] = X_temp.prod(axis=1)*prior_dct[k]\n",
    "\n",
    "num_dct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "d2cd218c34b141b8b483060dd46ce405",
    "deepnote_app_block_visible": false,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "* Create a new two-column pandas DataFrame with the results using the following code:\n",
    "```\n",
    "df_num = pd.DataFrame(num_dct)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "cell_id": "745857d554824606a9a40aa913281b26",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 401,
    "execution_start": 1713199517100,
    "source_hash": null
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fraud</th>\n",
       "      <th>Not Fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>396645</th>\n",
       "      <td>2.033245e-08</td>\n",
       "      <td>5.416763e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23311</th>\n",
       "      <td>1.084820e-08</td>\n",
       "      <td>3.816276e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898602</th>\n",
       "      <td>9.706474e-10</td>\n",
       "      <td>2.910761e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717543</th>\n",
       "      <td>3.315339e-09</td>\n",
       "      <td>4.215607e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777825</th>\n",
       "      <td>7.144284e-09</td>\n",
       "      <td>1.098875e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572344</th>\n",
       "      <td>5.347774e-08</td>\n",
       "      <td>8.761946e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452227</th>\n",
       "      <td>3.615439e-09</td>\n",
       "      <td>5.531373e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601337</th>\n",
       "      <td>1.001793e-08</td>\n",
       "      <td>2.572111e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722584</th>\n",
       "      <td>1.023674e-09</td>\n",
       "      <td>3.125787e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71530</th>\n",
       "      <td>3.222440e-09</td>\n",
       "      <td>5.922533e-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Fraud     Not Fraud\n",
       "396645  2.033245e-08  5.416763e-06\n",
       "23311   1.084820e-08  3.816276e-07\n",
       "898602  9.706474e-10  2.910761e-06\n",
       "717543  3.315339e-09  4.215607e-06\n",
       "777825  7.144284e-09  1.098875e-06\n",
       "...              ...           ...\n",
       "572344  5.347774e-08  8.761946e-06\n",
       "452227  3.615439e-09  5.531373e-06\n",
       "601337  1.001793e-08  2.572111e-09\n",
       "722584  1.023674e-09  3.125787e-06\n",
       "71530   3.222440e-09  5.922533e-06\n",
       "\n",
       "[100000 rows x 2 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_num = pd.DataFrame(num_dct)\n",
    "df_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "4bfcd533f257448a8f36c8007748f26f",
    "deepnote_app_block_visible": false,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "* What proportion of the values in `X_train` are correctly identified as Fraud using this procedure?  (Note.  We never actually need to compute the denominator in (4.30), since all we care about here is which entry is bigger.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "cell_id": "03c94911bbfd48a88ce48ebec0b9be2e",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 178,
    "execution_start": 1713199929275,
    "source_hash": null
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92776"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_num.idxmax(axis=1) == y_train).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "22f1d7228d364986aa21669211c1496c",
    "deepnote_app_block_visible": false,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Submission\n",
    "\n",
    "* Using the `Share` button at the top right, enable public sharing, and enable Comment privileges. Then submit the created link on Canvas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "ab2ddbc5cc1848b490284b7b760fd53e",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Possible extensions\n",
    "\n",
    "* I originally wanted us to consider log loss as our error metric, but I decided the lab was already getting rather long, so I removed that.  But in general, log loss is a more refined measure for detecting overfitting than accuracy score.  It should be relatively straightforward to evaluate log loss for the Logistic Regression model.  Compare this to the log loss of a baseline prediction, where we predict the same probability for every row.  I got some errors when I tried to evaluate log loss for the Naive Bayes model and I haven't thought carefully about how to avoid these.\n",
    "* How do our values compare to using the scikit-learn Naive Bayes model?  (I don't think this will be easy, because you will have to treat the Gaussian and the Boolean portions separately.  There might also be some discrepancy due to our method of estimating standard deviation, but I don't think that is crucial.  I have not tried this myself, so there could also be other discrepancies I'm not anticipating.)\n",
    "* How does KNN compare in performance?  (What's the optimal number of neighbors?)  I haven't tried this, and I think the training size might be too large, so be prepared to reduce the size of the training set further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=8bfb68aa-a490-4655-9dfb-cfa0891b3675' target=\"_blank\">\n",
    "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n",
    "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
   ]
  }
 ],
 "metadata": {
  "deepnote_notebook_id": "672349c36fe44fd4982a176dbb7a5237",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
